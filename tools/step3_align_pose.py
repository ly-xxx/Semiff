"""
Step 3: å¯å¾®å§¿æ€å¯¹é½
ä½¿ç”¨ SoftIoU Loss è¿›è¡Œç«¯åˆ°ç«¯çš„ Sim2Real å¯¹é½
"""

import sys
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import yourdfpy
import argparse
import logging
from pathlib import Path
from tqdm import tqdm
from omegaconf import OmegaConf

# Path hack to ensure imports work
sys.path.append(str(Path(__file__).parents[1] / "src"))

from semiff.core.math_utils import transform_points, rotation_6d_to_matrix, gpu_mem_guard
from semiff.core.losses import SoftIoULoss
from semiff.core.render import DifferentiableRasterizer
from semiff.core.workspace import WorkspaceManager  # [æ–°å¢]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Step3")


class PoseOptimizer(nn.Module):
    """å§¿æ€ä¼˜åŒ–å™¨ - å¯å¾®åˆ†åœ°ä¼˜åŒ–æœºå™¨äººå§¿æ€"""

    def __init__(self, urdf_path, init_pose, device='cuda'):
        super().__init__()
        self.device = device
        self.robot = yourdfpy.URDF.load(urdf_path)
        self._preload_meshes()

        # å¯å­¦ä¹ å‚æ•°
        # åŸºåº§æ—‹è½¬ (6D), å¹³ç§» (3), å…¨å±€ç¼©æ”¾ (1)
        self.rot_6d = nn.Parameter(torch.tensor([[1.0, 0.0, 0.0, 0.0, 1.0, 0.0]], device=device))
        self.trans = nn.Parameter(torch.tensor([init_pose[:3]], dtype=torch.float32, device=device))
        self.scale = nn.Parameter(torch.tensor([1.0], dtype=torch.float32, device=device))

    def _preload_meshes(self):
        """é¢„åŠ è½½URDF meshesç”¨äºæ‰¹æ¸²æŸ“"""
        self.meshes = {}
        for link in self.robot.link_names:
            mesh = self.robot.scene.geometry.get(link)
            if mesh:
                self.meshes[link] = {
                    'v': torch.from_numpy(mesh.vertices).float().to(self.device),
                    'f': torch.from_numpy(mesh.faces).int().to(self.device)
                }

    def forward(self, joint_cfg, rasterizer, K):
        """
        å‰å‘ä¼ æ’­ï¼šFK + å˜æ¢ + æ¸²æŸ“

        Args:
            joint_cfg: å…³èŠ‚é…ç½®å­—å…¸
            rasterizer: æ¸²æŸ“å™¨å®ä¾‹
            K: (3, 3) ç›¸æœºå†…å‚

        Returns:
            (1, H, W) é¢„æµ‹mask
        """
        # A. æ›´æ–°æ­£å‘è¿åŠ¨å­¦ (CPU å®‰å…¨)
        self.robot.update_cfg(joint_cfg)

        all_v = []
        all_f = []
        offset = 0

        # B. æ„é€ ä¸–ç•Œåæ ‡ç³»ä¸‹çš„mesh
        R_base = rotation_6d_to_matrix(self.rot_6d)[0]  # (3,3)

        for link, data in self.meshes.items():
            # T_link_local (FKç»“æœ)
            T_fk = torch.from_numpy(self.robot.get_transform(link)).float().to(self.device)

            # åº”ç”¨å¯å­¦ä¹ åŸºåº§å˜æ¢: T_world = T_base @ T_fk
            # æ³¨æ„ï¼šæˆ‘ä»¬ä¼˜åŒ– T_baseï¼ŒURDF FKæ˜¯ç›¸å¯¹äºåŸºåº§çš„
            # æ‰€ä»¥ P_world = s * (R_base @ (T_fk @ P_local) + t_base)

            # 1. æœ¬åœ° -> åŸºåº§åæ ‡ç³»
            v_base = transform_points(data['v'], T_fk)

            # 2. åŸºåº§åæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³» (å¯å­¦ä¹ )
            v_world = (v_base @ R_base.T) * self.scale + self.trans

            all_v.append(v_world)
            all_f.append(data['f'] + offset)
            offset += v_world.shape[0]

        full_v = torch.cat(all_v)
        full_f = torch.cat(all_f)

        # C. æ¸²æŸ“
        # æ‰©å±•åˆ°æ‰¹æ¬¡å¤§å° 1
        return rasterizer.render(full_v.unsqueeze(0), full_f, K.unsqueeze(0))


def run_step3(cfg_path):
    """è¿è¡ŒStep 3: å§¿æ€å¯¹é½"""
    # [æ–°å¢é€»è¾‘] ------------------------------------------------
    # Step 3 ä¾èµ– Step 1 çš„ processed_data.npz
    # å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œè‡ªåŠ¨å»æœ€æ–°çš„ valid workspace æ‰¾
    ws_mgr = WorkspaceManager(cfg_path)

    # ç­–ç•¥ï¼šå¯»æ‰¾åŒ…å« 'processed_data.npz' çš„æœ€æ–°ç›®å½•
    workspace = ws_mgr.resolve(mode="auto", required_input_files=["processed_data.npz"])

    #ä»¥æ­¤ workspace ä¸ºå‡†åŠ è½½é…ç½®
    runtime_cfg_path = workspace / "runtime_config.yaml"
    if runtime_cfg_path.exists():
        conf = OmegaConf.load(runtime_cfg_path)
    else:
        conf = OmegaConf.load(cfg_path) # Fallback
    # ----------------------------------------------------------

    device = conf.pipeline.device

    # Load Data (ä»è‡ªåŠ¨è§£æçš„ workspace åŠ è½½)
    data_path = workspace / "processed_data.npz"
    if not data_path.exists():
        logger.error(f"âŒ Input not found: {data_path}")
        return

    logger.info(f"ğŸ“‚ Loading data from: {data_path}")
    data = np.load(data_path)
    gt_mask = torch.from_numpy(data['mask']).float().unsqueeze(0).to(device)
    K = torch.from_numpy(data['intrinsic']).to(device)
    joint_cfg = data['qpos'].item()  # å…³èŠ‚é…ç½®
    H, W = data['img_size']

    # åˆå§‹åŒ–æ¨¡å‹
    urdf_path = Path(conf.data.root_dir) / conf.robot.urdf_rel_path
    logger.info(f"ğŸ”§ Loading URDF: {urdf_path}")
    model = PoseOptimizer(str(urdf_path), conf.alignment.init_trans, device=device)

    # è®¾ç½®æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    loss_fn = SoftIoULoss(smooth=conf.alignment.iou_smooth)
    optimizer = optim.Adam([
        {'params': model.rot_6d, 'lr': conf.optimization.lr_pose},
        {'params': model.trans, 'lr': conf.optimization.lr_trans},
        {'params': model.scale, 'lr': conf.optimization.lr_scale}
    ])

    rasterizer = DifferentiableRasterizer(H, W, device)

    # ä¼˜åŒ–å¾ªç¯
    logger.info("ğŸš€ Starting Pose Optimization...")
    with gpu_mem_guard():
        pbar = tqdm(range(conf.optimization.iterations))
        for i in pbar:
            optimizer.zero_grad()

            # é…ç½®: {'joint1': 0.0, ...}
            # joint_cfg = data['qpos']  # å®é™…åŠ è½½
            joint_cfg = {"joint1": 0.0}  # å ä½ç¬¦

            pred_mask = model(joint_cfg, rasterizer, K)

            loss = loss_fn(pred_mask, gt_mask)
            loss.backward()
            optimizer.step()

            pbar.set_description(".4f")

    # ä¿å­˜ç»“æœ
    out_path = Path(conf.pipeline.workspace) / "alignment.npz"

    # å¯¼å‡ºå‚æ•°
    R_final = rotation_6d_to_matrix(model.rot_6d)[0].detach().cpu().numpy()
    t_final = model.trans.detach().cpu().numpy()
    s_final = model.scale.detach().cpu().item()

    T_final = np.eye(4)
    T_final[:3, :3] = R_final * s_final
    T_final[:3, 3] = t_final

    np.savez(out_path, transform=T_final, scale=s_final)
    logger.info(f"âœ… Alignment saved to {out_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", default="configs/default.yaml")
    args = parser.parse_args()
    run_step3(args.config)