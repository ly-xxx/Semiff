# tools/run_segmentation_vis.py

import sys
import cv2
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
import hydra
from omegaconf import DictConfig
import os

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parents[1] / "src"))

from semiff.perception.sam2_wrapper import SAM2Wrapper
from semiff.core.logger import get_logger

logger = get_logger("vis_tool")

def is_headless():
    """æ£€æµ‹æ˜¯å¦åœ¨æ— å¤´ç¯å¢ƒä¸­è¿è¡Œ"""
    return os.environ.get('DISPLAY', '') == '' or not os.environ.get('DISPLAY')

@hydra.main(config_path="../src/semiff/config", config_name="defaults", version_base=None)
def main(cfg: DictConfig):
    logger.info("ğŸ¥ Starting Rapid Visualization Pipeline...")
    logger.info(f"Video path: {cfg.data.video_path}")
    logger.info(f"Output dir: {cfg.data.output_dir}")
    logger.info(f"Interactive mode: {cfg.pipeline.interactive_mode}")

    # æ£€æŸ¥æ˜¯å¦åœ¨æ— å¤´ç¯å¢ƒä¸­
    headless = is_headless()
    logger.info(f"Headless environment detected: {headless}")

    if headless:
        logger.info("Running in headless mode - will use automatic center point selection")
        cfg.pipeline.interactive_mode = False
    else:
        # å¼ºåˆ¶å¼€å¯äº¤äº’æ¨¡å¼
        cfg.pipeline.interactive_mode = True
        logger.info("Forced interactive mode to True")

    video_path = str(cfg.data.video_path)
    output_dir = Path(cfg.data.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. è¿è¡Œ SAM 2 åˆ†å‰²
    logger.info("Step 1: Running Segmentation...")
    print("Creating SAM2Wrapper...")
    sam2 = SAM2Wrapper(cfg)
    print("SAM2Wrapper created")

    # è¿™é‡Œ scene_cloud ä¼  Noneï¼Œå¼ºåˆ¶è§¦å‘æ‰‹åŠ¨ç‚¹å‡»
    print("Running SAM2...")
    result = sam2.run(video_path, output_dir, scene_cloud=None)
    print(f"SAM2 result: {result}")
    mask_dir = result['object_masks']
    print(f"Mask directory: {mask_dir}")

    # 2. ç”Ÿæˆå¯è§†åŒ–è§†é¢‘
    logger.info("Step 2: Rendering Visualization Video...")
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # ä¸¤ä¸ªè¾“å‡ºè§†é¢‘ï¼šä¸€ä¸ªæ˜¯é€æ˜èƒŒæ™¯(ç»¿å¹•)ï¼Œä¸€ä¸ªæ˜¯é«˜äº®å åŠ 
    out_overlay_path = output_dir / "vis_overlay.mp4"
    out_green_path = output_dir / "vis_green_screen.mp4"

    writer_overlay = cv2.VideoWriter(str(out_overlay_path), cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
    writer_green = cv2.VideoWriter(str(out_green_path), cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))

    frame_idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # åŠ è½½å¯¹åº”çš„ mask
        mask_path = mask_dir / f"{frame_idx:05d}.npz"
        if not mask_path.exists():
            break

        mask = np.load(mask_path)['mask'] # (H, W) boolean
        mask_uint8 = (mask * 255).astype(np.uint8)

        # === æ•ˆæœ 1: çº¢è‰²åŠé€æ˜å åŠ  (Overlay) ===
        # åˆ›å»ºçº¢è‰²é®ç½©
        red_mask = np.zeros_like(frame)
        red_mask[:, :, 2] = 255 # Red channel

        # æ··åˆï¼šåŸå›¾ + çº¢è‰²é®ç½© (åªåœ¨maskåŒºåŸŸ)
        overlay = frame.copy()
        # ä»…åœ¨ mask ä¸º True çš„åœ°æ–¹æ··åˆ
        overlay[mask] = cv2.addWeighted(frame[mask], 0.5, red_mask[mask], 0.5, 0)
        # ç”»è½®å»“
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(overlay, contours, -1, (0, 0, 255), 2)

        writer_overlay.write(overlay)

        # === æ•ˆæœ 2: ç»¿å¹•åˆ†ç¦» (Green Screen) ===
        # èƒŒæ™¯è®¾ä¸ºç»¿è‰² (0, 255, 0)
        green_bg = np.zeros_like(frame)
        green_bg[:] = (0, 255, 0)

        # å‰æ™¯æ‰£åƒ
        foreground = frame.copy()
        foreground[~mask] = green_bg[~mask]

        writer_green.write(foreground)

        frame_idx += 1
        if frame_idx % 20 == 0:
            print(f"Rendering frame {frame_idx}...", end='\r')

    cap.release()
    writer_overlay.release()
    writer_green.release()

    logger.info("âœ… Visualization saved to:")
    logger.info(f"   - {out_overlay_path} (ç”¨äºå±•ç¤ºåˆ†å‰²å‡†ç¡®åº¦)")
    logger.info(f"   - {out_green_path} (ç”¨äºå±•ç¤ºç‰©å—åˆ†ç¦»æ•ˆæœ)")

if __name__ == "__main__":
    main()
