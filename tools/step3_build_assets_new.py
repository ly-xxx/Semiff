"""
Step 3: Build Assets and Align with Robot
This step performs automatic Sim2Real alignment using Sapien-based robot sampling
and Gaussian Splatting ICP alignment.

Dependencies:
- pip install sapien open3d kornia
- pip install torch torchvision

Usage:
python tools/step3_build_assets.py
"""

import sys
import torch
import numpy as np
import open3d as o3d
from pathlib import Path

# æ·»åŠ  src è·¯å¾„
sys.path.insert(0, str(Path(__file__).parents[1] / "src"))

# å¼•å…¥å¤ç”¨çš„ real2sim æ¨¡å—
from semiff.utils.gs.gs_processor import GSProcessor
from semiff.utils.gs.icp_utils import global_registration_ransac, refine_with_icp, preprocess_for_features
from semiff.utils.robot.robot_pc_sampler import RobotPcSampler
from semiff.core.logger import get_logger

logger = get_logger("step3_assets")


def main():
    # === é…ç½® ===
    scan_ply_path = "outputs/splat/scene.ply"  # Step 2 è®­ç»ƒå‡ºçš„ 3DGS
    urdf_path = "assets/robots/xarm7_with_gripper.urdf"  # ä½ çš„ URDF
    output_dir = Path("outputs/assets")
    output_dir.mkdir(parents=True, exist_ok=True)

    print("ğŸš€ [Step 3] Building Assets with Robot Alignment...")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(scan_ply_path).exists():
        print(f"âŒ Scene PLY not found: {scan_ply_path}. Run Step 2 first.")
        return

    if not Path(urdf_path).exists():
        print(f"âŒ URDF not found: {urdf_path}. Check your robot URDF path.")
        return

    # 1. åˆå§‹åŒ– Robot Sampler (Sapien)
    # è¿™ä¼šåŠ è½½ URDF å¹¶å‡†å¤‡å¥½è¿åŠ¨å­¦
    print(f"Loading Robot URDF: {urdf_path}")
    try:
        sampler = RobotPcSampler(urdf_path)
    except Exception as e:
        print(f"âŒ Failed to load robot: {e}")
        print("Make sure Sapien is installed: pip install sapien")
        return

    # è®¾ç½®æœºå™¨äººå½“å‰çš„å…³èŠ‚è§’ (ä» Step 1 çš„æ—¥å¿—ä¸­è¯»å–ä¸€å¸§ï¼Œæˆ–è€…æ‰‹åŠ¨æŒ‡å®šä¸€ä¸ªå¯¹é½å§¿æ€)
    # å‡è®¾è¿™æ˜¯æœºå™¨äºº"ä¼¸ç›´"ä¾¿äºå¯¹é½çš„å§¿æ€
    qpos = np.zeros(7 + 2)  # 7è½´ + 2æŒ‡
    # æ¯”å¦‚ï¼š sampler.compute_robot_pcd éœ€è¦çš„æ˜¯å…³èŠ‚è§’
    print("Sampling robot point cloud...")
    try:
        robot_pts = sampler.compute_robot_pcd(qpos, num_pts=5000)
        print(f"Generated {len(robot_pts)} robot points")
    except Exception as e:
        print(f"âŒ Failed to sample robot point cloud: {e}")
        return

    # 2. åŠ è½½è§†è§‰åœºæ™¯ (3DGS)
    print("Loading Scene Splat...")
    try:
        sp = GSProcessor()
        gs_params = sp.load(scan_ply_path)
        scene_pts = gs_params['means3D'].cpu().numpy()
        print(f"Loaded {len(scene_pts)} scene points")
    except Exception as e:
        print(f"âŒ Failed to load scene: {e}")
        return

    # è½¬æ¢æˆ Open3D å¯¹è±¡ç”¨äº ICP
    source = o3d.geometry.PointCloud()
    source.points = o3d.utility.Vector3dVector(robot_pts)  # æºï¼šæœºå™¨äººæ ‡å‡†æ¨¡å‹
    source.paint_uniform_color([0, 1, 0])  # ç»¿

    target = o3d.geometry.PointCloud()
    target.points = o3d.utility.Vector3dVector(scene_pts)  # ç›®æ ‡ï¼šæ‰«æåœºæ™¯
    target.paint_uniform_color([1, 0, 0])  # çº¢

    # 3. è¿è¡Œè‡ªåŠ¨å¯¹é½ (RANSAC + ICP)
    # è¿™é‡Œçš„é€»è¾‘ç›´æ¥ç…§æ¬ icp_utils.py
    print("Running Alignment...")
    voxel_size = 0.02

    try:
        source_down, source_fpfh = preprocess_for_features(source, voxel_size)
        target_down, target_fpfh = preprocess_for_features(target, voxel_size)

        # 3.1 ç²—é…å‡†
        ransac_res = global_registration_ransac(
            source_down, target_down, source_fpfh, target_fpfh, voxel_size
        )
        print(".4f")

        # 3.2 ç²¾é…å‡†
        icp_coarse, icp_fine = refine_with_icp(
            source, target, ransac_res.transformation, voxel_size
        )
        T_world = icp_fine.transformation
        print("Final Transform (Sim -> Real):")
        print(T_world)

    except Exception as e:
        print(f"âŒ Alignment failed: {e}")
        return

    # 4. èµ„äº§ç”Ÿæˆä¸åˆ†å‰²
    # å°† GS å˜æ¢åˆ°æœºå™¨äººçš„åæ ‡ç³»ä¸‹ (Sim Frame)
    # æ³¨æ„ï¼šT_world æ˜¯ Robot -> Sceneï¼Œæˆ‘ä»¬éœ€è¦ Scene -> Robot
    T_inv = np.linalg.inv(T_world)

    print("Transforming scene to robot coordinate frame...")
    try:
        # å˜æ¢ GS å‚æ•°
        gs_params_aligned = sp.rotate(gs_params, torch.tensor(T_inv[:3, :3]).float().cuda())
        gs_params_aligned = sp.translate(gs_params_aligned, torch.tensor(T_inv[:3, 3]).float().cuda())

        # ç®€å•çš„ç©ºé—´åˆ†å‰²ï¼šåˆ‡æ‰æœºå™¨äººï¼ˆåŸç‚¹é™„è¿‘ï¼‰ï¼Œä¿ç•™ç‰©ä½“
        # è¿™é‡Œå¯ä»¥ç”¨ RobotPcSampler å†æ¬¡ç”Ÿæˆç‚¹äº‘æ¥åšæ›´ç²¾ç»†çš„ Mask å‰”é™¤
        # ... (æ­¤å¤„çœç•¥ KNN å‰”é™¤é€»è¾‘ï¼Œå‚è€ƒ segment_robot å‡½æ•°) ...

        # 5. ä¿å­˜
        aligned_ply_path = output_dir / "scene_aligned.ply"
        sp.save(gs_params_aligned, str(aligned_ply_path))
        np.save(output_dir / "T_world.npy", T_world)

        print("âœ… Assets generated and aligned!")
        print(f"ğŸ“ Aligned scene saved to: {aligned_ply_path}")
        print(f"ğŸ“ Transform saved to: {output_dir / 'T_world.npy'}")

        # ä¿å­˜èµ„äº§ä¿¡æ¯
        asset_info = {
            "scene_aligned_ply": str(aligned_ply_path),
            "transform_matrix": T_world.tolist(),
            "robot_qpos": qpos.tolist(),
            "robot_urdf": urdf_path,
            "alignment_method": "sapien_icp",
            "voxel_size": voxel_size
        }

        import json
        with open(output_dir / "asset_info.json", 'w') as f:
            json.dump(asset_info, f, indent=2)
        print(f"ğŸ“ Asset info saved to: {output_dir / 'asset_info.json'}")

    except Exception as e:
        print(f"âŒ Asset generation failed: {e}")
        return

    print("ğŸ¯ [Step 3] Asset generation completed!")
    print(f"ğŸ“ Assets saved to: {output_dir}")


if __name__ == "__main__":
    main()