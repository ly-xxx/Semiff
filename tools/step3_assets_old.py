import sys
from pathlib import Path
import numpy as np
import open3d as o3d
import cv2
from tqdm import tqdm

# æ·»åŠ  src è·¯å¾„
sys.path.insert(0, str(Path(__file__).parents[1] / "src"))
from semiff.geometry.meshing import Mesher
from semiff.geometry.decomposition import ColliderBuilder
from semiff.core.logger import get_logger

logger = get_logger("step3_assets")

def project_points_to_uv(points, K, T_cw):
    """å°†3Dç‚¹æŠ•å½±åˆ°2Dåƒç´ åæ ‡"""
    # points: (N, 3), T_cw: (4, 4) world -> camera, K: (3, 3)
    # 1. è½¬åˆ°ç›¸æœºåæ ‡ç³»
    R = T_cw[:3, :3]
    t = T_cw[:3, 3]
    pts_cam = points @ R.T + t

    # 2. æŠ•å½±
    pts_2d = pts_cam @ K.T
    uv = pts_2d[:, :2] / pts_2d[:, 2:3]
    return uv

def main():
    # é…ç½®è·¯å¾„ (å¯ä»¥åŽç»­æ”¹ç”¨ Hydra)
    base_dir = Path("outputs")
    ply_path = base_dir / "mast3r_result" / "scene.ply"
    poses_path = base_dir / "mast3r_result" / "poses.npy"
    mask_dir = base_dir / "masks_object"  # Step 2 çš„ç‰©ä½“æŽ©ç ç›®å½•
    output_asset_dir = base_dir / "assets"
    output_asset_dir.mkdir(exist_ok=True)

    print("ðŸš€ [Step 3] Asset Generation...")

    # æ£€æŸ¥ä¾èµ–æ–‡ä»¶
    if not ply_path.exists():
        print(f"âŒ Scene PLY not found: {ply_path}. Run Step 1 first.")
        return
    if not poses_path.exists():
        print(f"âŒ Poses file not found: {poses_path}. Run Step 1 first.")
        return
    if not mask_dir.exists():
        print(f"âŒ Object masks not found: {mask_dir}. Run Step 2 first.")
        return

    # 1. åŠ è½½ç‚¹äº‘å’Œä½å§¿
    print(f"Loading point cloud: {ply_path}")
    pcd = o3d.io.read_point_cloud(str(ply_path))
    points = np.asarray(pcd.points)
    colors = np.asarray(pcd.colors)
    poses = np.load(poses_path)  # (N_frames, 4, 4) camera-to-world
    print(f"Loaded {len(points)} points, {len(poses)} camera poses")

    # 2. ç®€åŒ–çš„å†…å‚ä¼°è®¡ (MASt3R è¾“å‡ºå½’ä¸€åŒ–åˆ° 512x512)
    H, W = 512, 512
    fx = fy = W * 0.8  # ç²—ç•¥ä¼°è®¡
    cx, cy = W / 2, H / 2
    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])
    print(f"Using camera intrinsics: fx={fx:.1f}, fy={fy:.1f}, cx={cx:.1f}, cy={cy:.1f}")

    # 3. è¿‡æ»¤ç‚¹äº‘ (Mask Filtering)
    # ç®€å•çš„æŠ•ç¥¨æœºåˆ¶ï¼šå¦‚æžœä¸€ä¸ªç‚¹åœ¨å¤šä¸ªè§†è§’çš„ Mask é‡Œï¼Œåˆ™ä¿ç•™
    point_votes = np.zeros(len(points), dtype=int)
    valid_frames = 0

    mask_files = sorted(list(mask_dir.glob("*.png")))
    print(f"Found {len(mask_files)} mask files")

    # é‡‡æ ·ä¸€äº›å¸§è¿›è¡Œè¿‡æ»¤ (é¿å…å¤ªæ…¢)
    sample_indices = np.linspace(0, len(mask_files)-1, min(10, len(mask_files))).astype(int)
    print(f"Sampling {len(sample_indices)} frames for filtering")

    for idx in tqdm(sample_indices, desc="Filtering points"):
        # è¯»å– Mask
        mask_path = mask_files[idx]
        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue

        mask = mask > 127  # äºŒå€¼åŒ–
        if mask.shape != (H, W):
            mask = cv2.resize(mask.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)

        # èŽ·å–è¯¥å¸§ä½å§¿ (World -> Camera)
        if idx >= len(poses):
            continue

        T_wc = poses[idx]
        T_cw = np.linalg.inv(T_wc)

        # æŠ•å½±æ‰€æœ‰ç‚¹
        uvs = project_points_to_uv(points, K, T_cw)

        # æ£€æŸ¥æ˜¯å¦åœ¨ Mask å†…
        u, v = uvs[:, 0].astype(int), uvs[:, 1].astype(int)
        valid_idx = (u >= 0) & (u < W) & (v >= 0) & (v < H)

        # ç´¯åŠ æŠ•ç¥¨ (ä»…å¯¹åœ¨è§†é”¥å†…çš„ç‚¹)
        in_mask = np.zeros(len(points), dtype=bool)
        in_mask[valid_idx] = mask[v[valid_idx], u[valid_idx]]

        point_votes[in_mask] += 1
        point_votes[~in_mask & valid_idx] -= 1  # å¦‚æžœåœ¨è§†é”¥å†…ä½†ä¸åœ¨maské‡Œï¼Œæ‰£åˆ†
        valid_frames += 1

    if valid_frames == 0:
        print("âŒ No valid frames found for filtering")
        return

    # ä¿ç•™åˆ†æ•° > 0 çš„ç‚¹
    object_indices = point_votes > 0
    obj_points = points[object_indices]
    obj_colors = colors[object_indices]

    print(f"Extracted {len(obj_points)} points for object (from {valid_frames} frames)")

    if len(obj_points) < 1000:
        print(f"âš ï¸ Warning: Only {len(obj_points)} points extracted. Object may be too small or poorly segmented.")
        return

    # 4. ä¿å­˜ç‰©ä½“ç‚¹äº‘
    obj_pcd = o3d.geometry.PointCloud()
    obj_pcd.points = o3d.utility.Vector3dVector(obj_points)
    obj_pcd.colors = o3d.utility.Vector3dVector(obj_colors)
    obj_ply_path = output_asset_dir / "object_raw.ply"
    o3d.io.write_point_cloud(str(obj_ply_path), obj_pcd)
    print(f"âœ… Saved object point cloud to {obj_ply_path}")

    # 5. ç”Ÿæˆ Mesh å’Œ Collision (è°ƒç”¨çŽ°æœ‰çš„ç±»)
    try:
        print("Running meshing...")
        mesher = Mesher()
        mesh_path = mesher.run(obj_points, output_path=str(output_asset_dir / "object.obj"))
        print(f"âœ… Mesh saved to {mesh_path}")

        print("Running collision decomposition...")
        collider = ColliderBuilder()
        collision_path = collider.decompose(mesh_path, output_path=str(output_asset_dir / "object_collision.obj"))
        print(f"âœ… Collision mesh saved to {collision_path}")

        # ä¿å­˜èµ„äº§ä¿¡æ¯
        asset_info = {
            "object_mesh": str(mesh_path),
            "object_collision": str(collision_path),
            "object_pointcloud": str(obj_ply_path),
            "point_count": len(obj_points),
            "extraction_frames": valid_frames
        }

        import json
        with open(output_asset_dir / "asset_info.json", 'w') as f:
            json.dump(asset_info, f, indent=2)
        print(f"âœ… Asset info saved to {output_asset_dir / 'asset_info.json'}")

    except Exception as e:
        print(f"âš ï¸ Mesh/collision generation failed: {e}")
        print("Object point cloud is still available for manual processing")

    print("ðŸŽ¯ [Step 3] Asset generation completed!")
    print(f"ðŸ“ Assets saved to: {output_asset_dir}")

if __name__ == "__main__":
    main()