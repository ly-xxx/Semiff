import os
import json
import torch
import numpy as np
import trimesh
from PIL import Image, ImageOps
from tqdm import tqdm

# === MASt3R / Dust3R ä¾èµ– ===
# ç¡®ä¿ä½ çš„ç¯å¢ƒé‡Œå¯ä»¥é€šè¿‡ 'from dust3r import ...' å¯¼å…¥
# å¦‚æœ mast3r ä»£ç åœ¨ third_party ä¸‹ï¼Œå¯èƒ½éœ€è¦ sys.path.append
import sys
sys.path.append("third_party/mast3r")

# è®¾ç½® dust3r è·¯å¾„ (å¿…é¡»åœ¨å¯¼å…¥ dust3r ä¹‹å‰)
import mast3r.utils.path_to_dust3r  # noqa

from dust3r.inference import inference
from mast3r.model import AsymmetricMASt3R
from dust3r.utils.image import load_images
from dust3r.image_pairs import make_pairs
from dust3r.cloud_opt import global_aligner, GlobalAlignerMode

# === é…ç½® ===
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# MASt3R æƒé‡è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ ä¸‹è½½çš„å®é™…è·¯å¾„)
MODEL_PATH = "checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth"
INPUT_DIR = "outputs/train_data/images"  # ä½ çš„ RGBA æˆ– RGB å›¾ç‰‡ç›®å½•
OUTPUT_DIR = "outputs/mast3r_result"
IMG_SIZE = 288  # é™ä½åˆ†è¾¨ç‡ä»¥èŠ‚çœæ˜¾å­˜ï¼Œ288 å¯¹ 12G æ˜¾å­˜æ›´å‹å¥½
SCHEDULE = "linear" # å­¦ä¹ ç‡è°ƒåº¦

def get_resized_image(pil_img, target_size=512):
    """
    å¼ºåˆ¶ç¼©æ”¾ï¼šæ‰€æœ‰å›¾ç‰‡ç¼©æ”¾åˆ°ç›¸åŒå°ºå¯¸ï¼Œä¸”ç¡®ä¿é•¿å®½å‡ä¸º 16 çš„å€æ•°ã€‚

    Args:
        pil_img: PIL Image å¯¹è±¡
        target_size: ç›®æ ‡å°ºå¯¸ (æ­£æ–¹å½¢ï¼Œå¿…é¡»æ˜¯ 16 çš„å€æ•°)
    """
    # å¼ºåˆ¶ç¼©æ”¾åˆ°æ­£æ–¹å½¢ï¼Œç¡®ä¿æ¨¡å‹å…¼å®¹æ€§
    resized_img = pil_img.resize((target_size, target_size), Image.Resampling.LANCZOS)

    return resized_img

def load_and_process_images(folder_path, size=512):
    """
    è¯»å–å›¾ç‰‡ï¼Œå¼ºåˆ¶ Exif æ—‹è½¬ï¼Œå¹¶è½¬æ¢ä¸º Tensor åˆ—è¡¨
    """
    image_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.png') or f.endswith('.jpg')])

    # å…³é”®å¸§é‡‡æ ·ï¼šå¦‚æœå›¾ç‰‡å¤ªå¤š(>100)ï¼Œæ¯éš” 5 å¸§å–ä¸€å¼ ï¼Œé˜²æ­¢æ˜¾å­˜çˆ†ç‚¸
    # 163å¸§ -> çº¦32å¸§ï¼Œè¶³ä»¥é‡å»ºåœºæ™¯ä¸”é€Ÿåº¦å¿«
    if len(image_files) > 50:
        print(f"âš ï¸ Image count {len(image_files)} is large. Sampling every 5th frame.")
        image_files = image_files[::5]

    imgs = []
    print("ğŸ“¸ Loading and preprocessing images...")
    for img_path in tqdm(image_files):
        # 1. æ‰“å¼€å›¾ç‰‡
        pil_img = Image.open(img_path).convert('RGB')

        # 2. ã€å…³é”®ã€‘Exif æ—‹è½¬ä¿®æ­£ (å¯¹é½ SAM2 åæ ‡ç³»)
        pil_img = ImageOps.exif_transpose(pil_img)

        # 3. å¼ºåˆ¶ç¼©æ”¾ (æ‰€æœ‰å›¾ç‰‡ç¼©æ”¾åˆ°ç›¸åŒå°ºå¯¸)
        pil_img = get_resized_image(pil_img, target_size=size)
        new_w, new_h = pil_img.size

        # 4. è½¬ Tensor: (1, 3, H, W)
        img_tensor = torch.from_numpy(np.array(pil_img)).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0).to(DEVICE)

        # å­˜å‚¨ä¸ºä¸€ä¸ª dict åˆ—è¡¨ï¼Œç¬¦åˆ Dust3R æ¥å£
        # true_shape åº”è¯¥æ˜¯ [[H, W]] æ ¼å¼çš„äºŒç»´æ•°ç»„
        imgs.append({'img': img_tensor, 'true_shape': np.array([[size, size]]), 'idx': len(imgs), 'instance': str(len(imgs))})

    return imgs, image_files

def run_mast3r_pipeline():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # 1. åŠ è½½æ¨¡å‹
    print(f"ğŸ¤– Loading MASt3R model from {MODEL_PATH}...")
    try:
        model = AsymmetricMASt3R.from_pretrained(MODEL_PATH).to(DEVICE)
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        print("ğŸ’¡ Tip: Ensure 'dust3r' and 'mast3r' are in your python path.")
        return

    # 2. å‡†å¤‡æ•°æ®
    imgs, file_paths = load_and_process_images(INPUT_DIR, size=IMG_SIZE)
    if len(imgs) < 2:
        print("âŒ Need at least 2 images!")
        return

    # 3. ç”Ÿæˆé…å¯¹ (Pair Generation) - ç˜¦èº«ç‰ˆç­–ç•¥
    # å¯¹äº 12G æ˜¾å­˜ï¼Œä½¿ç”¨ swin-3 ä¸”ä¸é€šè¿‡å¯¹ç§°åŠ å€ï¼Œå¤§å¹…å‡å°‘é…å¯¹æ•°
    print("ğŸ”— Generating image pairs (Lean Mode)...")
    pairs = make_pairs(imgs, scene_graph='swin-3', prefilter=None, symmetrize=False)

    # 4. æ¨¡å‹æ¨ç† (Inference)
    print("ğŸ§  Running inference (this may take a while)...")
    output = inference(pairs, model, DEVICE, batch_size=1, verbose=True)

    # 5. å…¨å±€ä¼˜åŒ– (Global Alignment)
    # è¿™æ˜¯ä»ä¸¤ä¸¤åŒ¹é…æ¢å¤å…¨å±€ç›¸æœºä½å§¿å’Œç‚¹äº‘çš„å…³é”®æ­¥éª¤
    print("ğŸŒ Running Global Alignment...")
    scene = global_aligner(output, device=DEVICE, mode=GlobalAlignerMode.PointCloudOptimizer)

    # æ˜¾å­˜å›æ”¶
    torch.cuda.empty_cache()

    # è¿è¡Œä¼˜åŒ– (pnp, ç„¦è·ä¼˜åŒ–ç­‰)
    loss = scene.compute_global_alignment(init="mst", niter=300, schedule=SCHEDULE, lr=0.01)
    print(f"âœ… Optimization done. Final Loss: {loss}")

    # 6. åå¤„ç†ä¸ä¿å­˜
    save_results(scene, file_paths)

def save_results(scene, file_paths):
    """
    å¯¼å‡ºä½å§¿ JSON å’Œç‚¹äº‘ PLY (å¢å¼ºé²æ£’æ€§ç‰ˆ)
    å…¼å®¹ Tensor/Numpyï¼Œè‡ªåŠ¨å¤„ç† CHW/HWC æ ¼å¼å·®å¼‚
    """
    print("ğŸ’¾ Saving results...")

    # --- 1. ä¿å­˜ä½å§¿ (Poses) ---
    try:
        # get_im_poses è¿”å›çš„æ˜¯ Tensorï¼Œéœ€è¦è½¬ numpy
    poses = scene.get_im_poses().detach().cpu().numpy()
    cameras_out = {}
    for idx, pose in enumerate(poses):
            # é˜²æ­¢ç´¢å¼•è¶Šç•Œï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
            if idx < len(file_paths):
                file_name = os.path.basename(file_paths[idx])
            else:
                file_name = f"unknown_{idx}.jpg"

        cameras_out[f"frame_{idx}"] = {
                "file": file_name,
            "transform_matrix": pose.tolist()
        }

    json_path = os.path.join(OUTPUT_DIR, "cameras.json")
    with open(json_path, 'w') as f:
        json.dump(cameras_out, f, indent=4)
    np.save(os.path.join(OUTPUT_DIR, "poses.npy"), poses)
    print(f"   -> Saved poses to {json_path}")
    except Exception as e:
        print(f"âš ï¸ Error saving poses: {e}")

    # --- 2. ä¿å­˜ç‚¹äº‘ (Point Cloud) ---
    print("   -> Merging point clouds...")

    # get_pts3d() è¿”å›é€šå¸¸æ˜¯ Tensor åˆ—è¡¨
    pts3d = scene.get_pts3d()

    all_pts = []
    all_colors = []

    for i in range(len(pts3d)):
        try:
            # --- A. å¤„ç†å‡ ä½•ä¿¡æ¯ (XYZ) ---
            pts_data = pts3d[i]
            if isinstance(pts_data, torch.Tensor):
                pts = pts_data.detach().cpu().numpy().reshape(-1, 3)
            else:
                pts = pts_data.reshape(-1, 3)

            # --- B. å¤„ç†é¢œè‰²ä¿¡æ¯ (RGB) - æ ¸å¿ƒä¿®å¤åŒº ---
            # 1. è·å–åŸå§‹æ•°æ®å¯¹è±¡
            img_entry = scene.imgs[i]
            # scene.imgs å¯èƒ½æ˜¯å­—å…¸åˆ—è¡¨ï¼Œä¹Ÿå¯èƒ½æ˜¯ç›´æ¥çš„å›¾åƒåˆ—è¡¨
            if isinstance(img_entry, dict):
                raw_img = img_entry['img']
            else:
                raw_img = img_entry

            # 2. ç»Ÿä¸€è½¬ä¸º Numpy
            if isinstance(raw_img, torch.Tensor):
                img_np = raw_img.detach().cpu().numpy()
            elif isinstance(raw_img, np.ndarray):
                img_np = raw_img
        else:
                print(f"âš ï¸ Frame {i}: Unknown image type {type(raw_img)}, skipping.")
                continue

            # 3. ç»´åº¦æ ‡å‡†åŒ– -> ç›®æ ‡æ ¼å¼ (H, W, 3)
            # æ­¤æ—¶ img_np å¯èƒ½æ˜¯ (1, 3, H, W), (3, H, W), æˆ– (H, W, 3)

            # æƒ…å†µ1: 4ç»´ (Batch, C, H, W) -> å»æ‰ Batch
            if img_np.ndim == 4:
                img_np = img_np.squeeze(0)

            # æƒ…å†µ2: 3ç»´ (C, H, W) é€šå¸¸ C=3 -> è½¬ç½®ä¸º (H, W, C)
            if img_np.ndim == 3 and img_np.shape[0] == 3 and img_np.shape[2] != 3:
                img_np = np.transpose(img_np, (1, 2, 0))

            # 4. å±•å¹³
            color = img_np.reshape(-1, 3)

            # 5. é¢œè‰²å€¼èŒƒå›´å½’ä¸€åŒ–æ£€æµ‹ (0-1 è¿˜æ˜¯ 0-255)
            # å¦‚æœæœ€å¤§å€¼å¾ˆå°(<=1.05)ï¼Œè®¤ä¸ºæ˜¯ float 0-1ï¼Œéœ€è¦ä¹˜ 255
            if color.max() <= 1.05:
        color = (color * 255).astype(np.uint8)
            else:
                color = color.astype(np.uint8)

            # --- C. è¿‡æ»¤ä¸åˆå¹¶ ---
            # è¿‡æ»¤æ‰åŸç‚¹ (0,0,0) æˆ–æ— æ•ˆæ·±åº¦ç‚¹
            # è®¡ç®—æ¯ä¸ªç‚¹çš„æ¨¡é•¿ï¼Œå¤ªå°çš„è§†ä¸ºæ— æ•ˆ
            norms = np.linalg.norm(pts, axis=1)
            valid_mask = norms > 1e-6

            # å†æ¬¡æ£€æŸ¥å½¢çŠ¶åŒ¹é…
            if len(pts) == len(color):
                all_pts.append(pts[valid_mask])
                all_colors.append(color[valid_mask])
            else:
                # å¦‚æœå½¢çŠ¶ä¸åŒ¹é…ï¼Œå°è¯• resize color (æå…¶ç½•è§ä½†åœ¨ resizing é€»è¾‘ä¸ä¸¥è°¨æ—¶ä¼šå‘ç”Ÿ)
                print(f"âš ï¸ Frame {i} mismatch: pts {pts.shape} vs color {color.shape}. Skipping.")

        except Exception as step_e:
            print(f"âš ï¸ Error processing frame {i}: {step_e}")
            import traceback
            traceback.print_exc()
            continue

    # --- D. å¯¼å‡ºæœ€ç»ˆæ–‡ä»¶ ---
    if all_pts:
        final_pts = np.concatenate(all_pts, axis=0)
        final_colors = np.concatenate(all_colors, axis=0)

        ply_path = os.path.join(OUTPUT_DIR, "scene.ply")
        try:
            # ä¼˜å…ˆä½¿ç”¨ Trimesh
            pcd = trimesh.PointCloud(vertices=final_pts, colors=final_colors)
        pcd.export(ply_path)
            print(f"âœ… Success! Saved colored point cloud to {ply_path} ({len(final_pts)} points)")
        except Exception as e:
            print(f"âŒ Trimesh export failed: {e}. Falling back to text format.")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šçº¯æ–‡æœ¬å†™å…¥
            header = "ply\nformat ascii 1.0\nelement vertex {}\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\nproperty uchar green\nproperty uchar blue\nend_header".format(len(final_pts))
            np.savetxt(ply_path,
                       np.hstack((final_pts, final_colors)),
                       fmt='%.6f %.6f %.6f %d %d %d',
                       header=header, comments='')
            print(f"   (Fallback) Saved raw PLY to {ply_path}")
    else:
        print("âŒ Error: No valid points generated from any frame.")

if __name__ == "__main__":
    # æ˜¾å­˜æ¸…ç†
    torch.cuda.empty_cache()
    run_mast3r_pipeline()