import argparse
import json
import numpy as np
import logging
import cv2
import subprocess
import sys
import pandas as pd
import warnings
import shutil
from pathlib import Path
from tqdm import tqdm
from omegaconf import OmegaConf, open_dict

warnings.filterwarnings("ignore")

# ÂØºÂÖ•Áªü‰∏ÄË∑ØÂæÑÁÆ°ÁêÜÂ∑•ÂÖ∑
_current_file = Path(__file__).resolve()
_src_dir = _current_file.parents[1] / "src"
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))

from semiff.core.workspace import WorkspaceManager

# üîß ‰ΩøÁî®Áªü‰∏ÄÊñπÊ≥ïËé∑ÂèñÈ°πÁõÆÊ†πÁõÆÂΩï
PROJECT_ROOT = WorkspaceManager.find_project_root(start_path=_current_file.parent)

try:
    from semiff.solvers.sam2_wrapper import SAM2Wrapper
except ImportError:
    SAM2Wrapper = None

# üÜï Â∞ùËØïÂØºÂÖ• SAM 3 Wrapper
try:
    from semiff.solvers.sam3_wrapper import SAM3Wrapper
except ImportError:
    SAM3Wrapper = None

try:
    from semiff.solvers.mast3r_wrapper import MASt3RWrapper
except ImportError:
    MASt3RWrapper = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Step1")

# ... (ËæÖÂä©ÂáΩÊï∞ get_video_rotation Âíå FFmpegWriter ‰øùÊåÅ‰∏çÂèòÔºåÊ≠§Â§ÑÁúÅÁï•‰ª•ËäÇÁúÅÁØáÂπÖ) ...

def get_video_rotation(video_path):
    # (‰øùÊåÅÂéüÊ†∑)
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', str(video_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0: return None, False
        data = json.loads(result.stdout)
        video_stream = next((s for s in data.get('streams', []) if s['codec_type'] == 'video'), None)
        if not video_stream: return None, False
        rotate = int(video_stream.get('tags', {}).get('rotate', 0))
        if rotate != 0: logger.info(f"üïµÔ∏è Metadata Rotation Tag: {rotate}¬∞")
        if rotate == 90: return cv2.ROTATE_90_CLOCKWISE, True
        elif rotate == 180: return cv2.ROTATE_180, False
        elif rotate == 270: return cv2.ROTATE_90_COUNTERCLOCKWISE, True
        elif rotate == -90: return cv2.ROTATE_90_COUNTERCLOCKWISE, True
        else: return None, False
    except: return None, False

def run_step1():
    base_config_path = PROJECT_ROOT / "configs" / "base_config.yaml"
    base_cfg = OmegaConf.load(base_config_path)

    # 1. Âü∫Á°ÄÂèÇÊï∞ËØªÂèñ (‚úÖ Ê£ÄÊü•ÈÄöËøá)
    workspace_mode = base_cfg.pipeline.get("mode", "auto")
    root_dir = base_cfg.data.get("root_dir", "data/example_01")
    video_path_rel = base_cfg.data.get("video_path", "video.mp4")

    dataset_dir = Path(root_dir) if Path(root_dir).is_absolute() else PROJECT_ROOT / root_dir
    video_path = dataset_dir / video_path_rel

    ws_mgr = WorkspaceManager(str(base_config_path))
    workspace = ws_mgr.resolve(mode=workspace_mode)
    logger.info(f"üìÇ Workspace: {workspace}")

    runtime_cfg_path = workspace / "runtime_config.yaml"
    cfg = OmegaConf.merge(OmegaConf.load(runtime_cfg_path), base_cfg) if runtime_cfg_path.exists() else base_cfg

    # 2. Ê≠•È™§ÂºÄÂÖ≥ËØªÂèñ (‚úÖ Ê£ÄÊü•ÈÄöËøá)
    ENABLE_SAM2 = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_sam2", False)
    ENABLE_SAM3 = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_sam3", True)
    ENABLE_MAST3R = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_mast3r", True)

    mask_obj_dir = workspace / "masks_object"
    mask_robot_dir = workspace / "masks_robot"
    images_dir = workspace / "images"
    for d in [mask_obj_dir, mask_robot_dir, images_dir]: d.mkdir(exist_ok=True)

    # 3. ÊóãËΩ¨Ê£ÄÊµãÈÄªËæë (‚úÖ Ê£ÄÊü•ÈÄöËøá)
    rotate_code, is_vertical_meta = get_video_rotation(video_path)
    temp_cap = cv2.VideoCapture(str(video_path))
    ret, temp_frame = temp_cap.read()
    temp_cap.release()
    if not ret: raise RuntimeError(f"Cannot read video: {video_path}")
    h_raw, w_raw = temp_frame.shape[:2]

    need_manual_rotate = False
    if is_vertical_meta and w_raw > h_raw:
        need_manual_rotate = True
        logger.info(f"üîÑ Manual Rotation Required: Metadata says Vertical, but Raw is {w_raw}x{h_raw}")
    else:
        logger.info(f"‚úÖ No Manual Rotation Needed. Raw frame is naturally {w_raw}x{h_raw}")
        if w_raw < h_raw: rotate_code = None

    if need_manual_rotate: w_out, h_out = h_raw, w_raw
    else: w_out, h_out = w_raw, h_raw
    logger.info(f"üìê Target Dims: {w_out}x{h_out}")

    # üî•üî•„Äê‰øÆÂ§ç 1„Äë: Â∞ÜËÆ°ÁÆóÂá∫ÁöÑ rotate_code Ê≥®ÂÖ•Âà∞ cfg ‰∏≠ üî•üî•
    # ÂøÖÈ°ª‰ΩøÁî® open_dict ‰∏ä‰∏ãÊñáÊâçËÉΩ‰øÆÊîπ OmegaConf ÂØπË±°
    effective_rotate_code = int(rotate_code) if (need_manual_rotate and rotate_code is not None) else None

    with open_dict(cfg):
        if 'pipeline' not in cfg: cfg.pipeline = {}
        # ÊòæÂºèÂÜôÂÖ•ÔºåÁ°Æ‰øù Wrapper ËÉΩËØªÂà∞ 'input_rotate_code'
        cfg.pipeline.input_rotate_code = effective_rotate_code
        logger.info(f"üîß Config Injection: pipeline.input_rotate_code = {effective_rotate_code}")

    # ‰øùÂ≠òÊúÄÁªà‰ΩøÁî®ÁöÑÈÖçÁΩÆÔºàÂåÖÂê´Ê≥®ÂÖ•ÁöÑÊóãËΩ¨ÂèÇÊï∞Ôºâ
    OmegaConf.save(cfg, runtime_cfg_path)

    rgb_frames_buffer = []
    masks_buffer = []

    # === Phase A: Segmentation ===
    active_segmenter = None
    if ENABLE_SAM3 and SAM3Wrapper:
        logger.info("üöÄ [SAM3] Initializing Text-Driven Segmentation...")
        # SAM3Wrapper ÂÜÖÈÉ®ÈÄöÂ∏∏‰ºöËØªÂèñ cfg.sam3 Âíå cfg.pipelineÔºåËøôÈáå‰º†ÂÖ•ÂÆåÊï¥ cfg ÊòØÂØπÁöÑ
        active_segmenter = SAM3Wrapper(cfg)

    elif ENABLE_SAM2 and SAM2Wrapper:
        logger.info("üé® [SAM2] Initializing Segmentation...")
        # SAM2Wrapper Áé∞Âú®ÂèØ‰ª•Áõ¥Êé•‰ªé cfg.sam2 ËØªÂèñÈÖçÁΩÆ
        active_segmenter = SAM2Wrapper(cfg)

    if active_segmenter:
        generator = active_segmenter.run_generator(str(video_path), output_dir=workspace)
        cap_read = cv2.VideoCapture(str(video_path))
        
        # üé¨ ÂàõÂª∫ÂèØËßÜÂåñÂ∏ß‰∏¥Êó∂ÁõÆÂΩï
        vis_frames_dir = workspace / "vis_frames_temp"
        vis_frames_dir.mkdir(exist_ok=True)
        
        # Ëé∑ÂèñÂéüËßÜÈ¢ëÂ∏ßÁéá
        fps = cap_read.get(cv2.CAP_PROP_FPS)
        if fps == 0 or fps > 120:  # Èò≤Ê≠¢ÂºÇÂ∏∏ÂÄº
            fps = 30.0
        logger.info(f"üìπ Video FPS: {fps}")

        current_idx = 0
        try:
            total_frames = int(cap_read.get(cv2.CAP_PROP_FRAME_COUNT))
            pbar = tqdm(total=total_frames, desc="Segmenting")

            for result in generator:
                if result.get("status") == "cancelled": break
                frame_idx = result["frame_idx"]
                all_masks = result["masks"]

                while current_idx <= frame_idx:
                    ret, raw_frame = cap_read.read()
                    current_idx += 1
                if not ret: break

                if need_manual_rotate and rotate_code is not None:
                    frame_upright = cv2.rotate(raw_frame, rotate_code)
                else:
                    frame_upright = raw_frame

                cv2.imwrite(str(images_dir / f"{frame_idx:05d}.png"), frame_upright)
                rgb_frames_buffer.append(cv2.cvtColor(frame_upright, cv2.COLOR_BGR2RGB))

                vis_frame = frame_upright.copy()

                # Robot Mask (ID 2)
                robot_mask = np.zeros((h_out, w_out), dtype=np.uint8)
                if 2 in all_masks:
                    m = (all_masks[2] * 255).astype(np.uint8)
                    if m.shape[:2] != (h_out, w_out):
                        m = cv2.resize(m, (w_out, h_out), interpolation=cv2.INTER_NEAREST)
                    robot_mask = m
                    bool_mask = robot_mask > 0

                    if bool_mask.any():
                        color = np.array([255, 0, 0], dtype=np.uint8)  # ËìùËâ≤
                        roi = vis_frame[bool_mask]
                        blended = (roi * 0.5 + color * 0.5).astype(np.uint8)
                        vis_frame[bool_mask] = blended

                # Object Mask (ID 1)
                object_mask = np.zeros((h_out, w_out), dtype=np.uint8)
                if 1 in all_masks:
                    m = (all_masks[1] * 255).astype(np.uint8)
                    if m.shape[:2] != (h_out, w_out):
                        m = cv2.resize(m, (w_out, h_out), interpolation=cv2.INTER_NEAREST)
                    object_mask = m
                    bool_mask = object_mask > 0

                    if bool_mask.any():
                        color = np.array([0, 255, 255], dtype=np.uint8)  # ÈùíËâ≤
                        roi = vis_frame[bool_mask]
                        blended = (roi * 0.5 + color * 0.5).astype(np.uint8)
                        vis_frame[bool_mask] = blended

                cv2.imwrite(str(mask_robot_dir / f"{frame_idx:05d}.png"), robot_mask)
                cv2.imwrite(str(mask_obj_dir / f"{frame_idx:05d}.png"), object_mask)
                
                # üÜï ‰øùÂ≠òÂèØËßÜÂåñÂ∏ßÂà∞‰∏¥Êó∂ÁõÆÂΩï
                cv2.imwrite(str(vis_frames_dir / f"{frame_idx:05d}.png"), vis_frame)

                masks_buffer.append(robot_mask)
                pbar.update(1)
            pbar.close()
        finally:
            cap_read.release()
            logger.info("‚úÖ Segmentation Done.")
        
        # üé¨ ‰ΩøÁî® ffmpeg ÂêàÊàêËßÜÈ¢ë
        video_save_path = workspace / "vis_segmentation.mp4"
        logger.info(f"üé• Encoding video with ffmpeg: {video_save_path}")
        
        ffmpeg_cmd = [
            'ffmpeg',
            '-y',  # Ë¶ÜÁõñÂ∑≤Â≠òÂú®ÁöÑÊñá‰ª∂
            '-framerate', str(fps),
            '-i', str(vis_frames_dir / '%05d.png'),
            '-c:v', 'libx264',  # H.264 ÁºñÁ†Å
            '-preset', 'medium',  # ÁºñÁ†ÅÈÄüÂ∫¶ (faster/medium/slow)
            '-crf', '23',  # Ë¥®Èáè (18-28, Ë∂äÂ∞èË¥®ÈáèË∂äÂ•Ω)
            '-pix_fmt', 'yuv420p',  # ÂÖºÂÆπÊÄßÊúÄÂ•Ω
            str(video_save_path)
        ]
        
        try:
            result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, check=True)
            logger.info(f"‚úÖ Video saved: {video_save_path}")
            
            # Ê∏ÖÁêÜ‰∏¥Êó∂Â∏ß
            shutil.rmtree(vis_frames_dir)
            logger.info("üßπ Cleaned up temporary frames")
            
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå ffmpeg failed: {e.stderr}")
            logger.warning(f"‚ö†Ô∏è  Temporary frames kept at: {vis_frames_dir}")

    # ... (Phase B: MASt3R ÈÄªËæë‰øùÊåÅ‰∏çÂèò) ...
    # ‰∏∫‰∫ÜÂÆåÊï¥ÊÄßÔºåËØ∑‰øùÁïôÂéüÊúâÁöÑ MASt3R ‰ª£Á†ÅÂùó
    if ENABLE_MAST3R and MASt3RWrapper is not None and len(rgb_frames_buffer) > 0:
        # (ÂéüÊ†∑‰øùÁïô Phase B ‰ª£Á†Å)
        logger.info(f"üß† [MASt3R] Reconstruction with {len(rgb_frames_buffer)} frames...")
        mast3r = MASt3RWrapper(device="cuda")
        debug_dir = workspace / "debug_mast3r"
        debug_dir.mkdir(exist_ok=True)

        poses, cloud, intrinsics = mast3r.run(
            frames=rgb_frames_buffer,
            masks=masks_buffer,
            keyframe_interval=2,
            debug_dir=debug_dir
        )

        np.save(workspace / "camera_poses.npy", poses)
        np.save(workspace / "sparse_cloud.npy", cloud)
        np.save(workspace / "intrinsics.npy", intrinsics)

        # PLY ‰øùÂ≠òÈÄªËæë
        if cloud.shape[0] > 0:
            ply_path = workspace / "sparse_cloud.ply"

            xyz = cloud[:, :3]
            rgb = cloud[:, 3:6].astype(np.uint8)
            lbl = cloud[:, 6].astype(np.uint8)

            header = (
                "ply\n"
                "format ascii 1.0\n"
                f"element vertex {len(cloud)}\n"
                "property float x\n"
                "property float y\n"
                "property float z\n"
                "property uchar red\n"
                "property uchar green\n"
                "property uchar blue\n"
                "property uchar label\n"
                "end_header\n"
            )

            with open(ply_path, "w") as f:
                f.write(header)
                for p, c, l in zip(xyz, rgb, lbl):
                    f.write(f"{p[0]:.4f} {p[1]:.4f} {p[2]:.4f} {int(c[0])} {int(c[1])} {int(c[2])} {int(l)}\n")

            logger.info(f"‚úÖ Saved LABELED point cloud to {ply_path}")
            logger.info("‚ÑπÔ∏è  Use 'label' scalar field in CloudCompare/MeshLab to isolate robot.")
    else:
        if len(rgb_frames_buffer) == 0: logger.error("‚ùå No frames loaded!")

if __name__ == "__main__":
    run_step1()