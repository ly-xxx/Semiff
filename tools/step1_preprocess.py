import argparse
import json
import numpy as np
import logging
import cv2
import subprocess
import sys
from pathlib import Path
from tqdm import tqdm
from omegaconf import OmegaConf

# ==================== 1. æ ¸å¿ƒè·¯å¾„é…ç½® ====================
# åŠ¨æ€è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(PROJECT_ROOT / "src"))

# >>> æ•°æ®é›†åç§° <<<
DATASET_NAME = "example_01" 
# =======================================================

from semiff.core.workspace import WorkspaceManager
try:
    from semiff.perception.sam2_wrapper import SAM2Wrapper
except ImportError:
    pass 
try:
    from semiff.perception.mast3r_wrapper import MASt3RWrapper
except ImportError:
    pass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Step1")

# ==================== è¾…åŠ©ç±» ====================
class FFmpegWriter:
    def __init__(self, filename, width, height, fps):
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        self.cmd = [
            'ffmpeg', '-y', '-f', 'rawvideo', '-vcodec', 'rawvideo',
            '-s', f'{width}x{height}', '-pix_fmt', 'bgr24', '-r', f'{fps}',
            '-i', '-', '-c:v', 'libx264', '-pix_fmt', 'yuv420p',
            '-preset', 'fast', '-crf', '23', str(filename)
        ]
        self.process = subprocess.Popen(
            self.cmd, stdin=subprocess.PIPE, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE
        )

    def write(self, frame):
        try:
            self.process.stdin.write(frame.tobytes())
        except BrokenPipeError:
            pass

    def release(self):
        if self.process:
            self.process.stdin.close()
            self.process.wait()

# ==================== ä¸»æµç¨‹ ====================
def run_step1():
    # -----------------------------------------------------
    # 1. è·¯å¾„ç»„è£…
    # -----------------------------------------------------
    base_config_path = PROJECT_ROOT / "configs" / "base_config.yaml"
    dataset_dir = PROJECT_ROOT / "data" / DATASET_NAME
    video_path = dataset_dir / "video.mp4"
    robot_config_path = dataset_dir / "config" / "align_pose.json"

    if not base_config_path.exists():
        logger.error(f"âŒ Base config not found: {base_config_path}")
        return
    if not video_path.exists():
        logger.error(f"âŒ Video file not found: {video_path}")
        return

    # -----------------------------------------------------
    # 2. å¯åŠ¨å·¥ä½œåŒº
    # -----------------------------------------------------
    ws_mgr = WorkspaceManager(str(base_config_path))
    workspace = ws_mgr.resolve(mode="new")
    logger.info(f"ğŸš€ [Step 1] Dataset: {DATASET_NAME}")
    logger.info(f"ğŸ“‚ Workspace Created: {workspace}")

    # -----------------------------------------------------
    # 3. é…ç½®ç®¡ç†
    # -----------------------------------------------------
    cfg = OmegaConf.load(base_config_path)
    
    # ä¿®æ­£ç›¸å¯¹è·¯å¾„
    cfg.checkpoint = str(PROJECT_ROOT / cfg.get("checkpoint", "checkpoints/sam2_hiera_large.pt"))
    cfg.model_cfg = str(PROJECT_ROOT / cfg.get("model_cfg", "configs/sam2.1/sam2.1_hiera_l.yaml"))
    
    # è¦†ç›–æ•°æ®è·¯å¾„
    cfg.data.video_path = str(video_path)
    cfg.data.robot_config = str(robot_config_path)
    cfg.dataset_name = DATASET_NAME
    
    OmegaConf.save(cfg, workspace / "runtime_config.yaml")

    # -----------------------------------------------------
    # 4. å‡†å¤‡è¾“å‡ºç›®å½•
    # -----------------------------------------------------
    mask_obj_dir = workspace / "masks_object"
    mask_robot_dir = workspace / "masks_robot"
    images_dir = workspace / "images"  # æ–°å¢ï¼šç”¨äºå­˜å‚¨ RGB å¸§ç»™ Step 2 ä½¿ç”¨
    
    mask_obj_dir.mkdir(exist_ok=True)
    mask_robot_dir.mkdir(exist_ok=True)
    images_dir.mkdir(exist_ok=True)

    # -----------------------------------------------------
    # 5. åˆå§‹åŒ– SAM 2 & è§†é¢‘å±æ€§
    # -----------------------------------------------------
    sam2 = SAM2Wrapper(cfg)
    
    # æ£€æµ‹æ—‹è½¬
    detected_rotate = sam2._detect_video_rotation(video_path)
    rotate_code = cfg.pipeline.get("input_rotate_code", None)
    if rotate_code is None: rotate_code = detected_rotate
    if rotate_code is not None: logger.info(f"ğŸ”„ Rotation Applied: {rotate_code}")

    # è§†é¢‘å‚æ•°
    cap = cv2.VideoCapture(str(video_path))
    w_raw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h_raw = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()

    # è¾“å‡ºå°ºå¯¸
    swap_dims = rotate_code in [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE]
    w_out, h_out = (h_raw, w_raw) if swap_dims else (w_raw, h_raw)
    if w_out % 2 != 0: w_out -= 1
    if h_out % 2 != 0: h_out -= 1

    vis_writer = FFmpegWriter(workspace / "segmentation_vis.mp4", w_out, h_out, fps)

    # -----------------------------------------------------
    # 6. æ‰§è¡Œæ„ŸçŸ¥å¾ªç¯ (SAM 2 + å›¾åƒæå–)
    # -----------------------------------------------------
    logger.info("ğŸ¨ Starting Segmentation & Frame Extraction...")
    generator = sam2.run_generator(str(video_path))
    
    pbar = tqdm(total=total_frames, unit="frame", desc="Processing")
    cap_read = cv2.VideoCapture(str(video_path))
    current_idx = 0

    # æ”¶é›†æ¯ä¸€å¸§ï¼ˆæ—‹è½¬åï¼‰ç”¨äº MASt3R
    # æ³¨æ„ï¼šå¦‚æœæ˜¾å­˜æœ‰é™ï¼Œè¿™é‡Œå¯ä»¥åªå­˜è·¯å¾„ï¼Œä½† MASt3R Wrapper éœ€è¦ np.ndarray
    rgb_frames_buffer = [] 

    try:
        for result in generator:
            if result.get("status") == "cancelled":
                logger.warning("ğŸš« Segmentation Cancelled.")
                break
            
            frame_idx = result["frame_idx"]
            all_masks = result["masks"]

            # åŒæ­¥è¯»å–åŸè§†é¢‘
            while current_idx <= frame_idx:
                ret, frame = cap_read.read()
                current_idx += 1
                if not ret: break
            if not ret: break

            # 1. æ—‹è½¬ä¸ç¼©æ”¾ (ç»Ÿä¸€æ ‡å‡†)
            if rotate_code is not None:
                frame = cv2.rotate(frame, rotate_code)
            if frame.shape[1] != w_out or frame.shape[0] != h_out:
                frame = cv2.resize(frame, (w_out, h_out))

            # 2. ä¿å­˜ RGB å¸§ (ç»™ 3DGS ä½¿ç”¨)
            # MASt3R å’Œ 3DGS éƒ½éœ€è¦è¿™äº›å¤„ç†è¿‡çš„å›¾ç‰‡
            frame_filename = f"{frame_idx:05d}.png"
            cv2.imwrite(str(images_dir / frame_filename), frame)
            
            # 3. å­˜å…¥ Buffer (ç»™ MASt3R ä½¿ç”¨)
            # ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œå¦‚æœè§†é¢‘æé•¿ï¼Œå¯ä»¥è€ƒè™‘åªå­˜å…³é”®å¸§ï¼Œ
            # ä½† MASt3R Wrapper ä¼šè‡ªå·±å¤„ç†é—´éš”ã€‚
            # è¿™é‡Œå­˜ BGR -> RGB (MASt3R éœ€è¦ RGB)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            rgb_frames_buffer.append(rgb_frame)

            # 4. å¤„ç† Mask & å¯è§†åŒ–
            vis = frame.copy()
            for obj_id, mask in all_masks.items():
                mask_uint8 = mask.astype(np.uint8) * 255
                if rotate_code is not None:
                    mask_uint8 = cv2.rotate(mask_uint8, rotate_code)
                if mask_uint8.shape[:2] != (h_out, w_out):
                    mask_uint8 = cv2.resize(mask_uint8, (w_out, h_out), interpolation=cv2.INTER_NEAREST)

                if obj_id == 1: # Object
                    cv2.imwrite(str(mask_obj_dir / frame_filename), mask_uint8)
                    vis[mask_uint8 > 127] = cv2.addWeighted(vis[mask_uint8 > 127], 0.5, np.array([0,0,255]), 0.5, 0)
                elif obj_id == 2: # Robot
                    cv2.imwrite(str(mask_robot_dir / frame_filename), mask_uint8)
                    vis[mask_uint8 > 127] = cv2.addWeighted(vis[mask_uint8 > 127], 0.5, np.array([255,0,0]), 0.5, 0)

            vis_writer.write(vis)
            pbar.update(1)

    except KeyboardInterrupt:
        logger.warning("Interrupted.")
    finally:
        pbar.close()
        vis_writer.release()
        cap_read.release()

    # -----------------------------------------------------
    # 7. 3D å§¿æ€ä¼°è®¡ (MASt3R)
    # -----------------------------------------------------
    logger.info("ğŸ“· Running MASt3R for 3D Pose Estimation...")
    
    mast3r = MASt3RWrapper(device="cuda")
    
    # å…³é”®å¸§é—´éš”ï¼šæ ¹æ®æ˜¾å­˜å’Œè§†é¢‘é•¿åº¦è°ƒæ•´ï¼Œé»˜è®¤ 15
    keyframe_interval = 15
    # æ³¨æ„ï¼šæˆ‘ä»¬å·²ç»æ‰‹åŠ¨æ—‹è½¬è¿‡å›¾ç‰‡äº†ï¼Œè¿™é‡Œä¼  None é˜²æ­¢é‡å¤æ—‹è½¬
    poses, cloud = mast3r.run(rgb_frames_buffer, keyframe_interval=keyframe_interval, rotate_code=None)
    
    # ä¿å­˜ç»“æœ
    if len(poses) > 0:
        # A. ç”Ÿæˆ transforms.json (3DGS æ ¼å¼)
        transforms = {
            "camera_model": "PINHOLE",
            "frames": []
        }
        
        # ä¼°ç®—å†…å‚ (å¦‚æœ MASt3R æœªè¿”å›ï¼Œä½¿ç”¨è§†åœºè§’ä¼°ç®—)
        # å‡è®¾ HFOV ~ 60åº¦ -> fl ~ w * 0.8
        fl_x = w_out * 1.0 
        fl_y = w_out * 1.0
        cx = w_out / 2.0
        cy = h_out / 2.0

        for i, pose in enumerate(poses):
            # æ‰¾åˆ°å¯¹åº”çš„çœŸå®å¸§ ID
            real_idx = i * keyframe_interval
            
            # Nerfstudio / 3DGS é€šå¸¸æœŸæœ› OpenGL åæ ‡ç³»
            # MASt3R è¾“å‡ºé€šå¸¸æ˜¯å¯¹é½çš„ï¼Œè¿™é‡Œç›´æ¥ä¿å­˜ï¼Œåç»­è§†æƒ…å†µåœ¨ Step 2 è°ƒæ•´
            frame_entry = {
                "file_path": f"images/{real_idx:05d}.png",
                "transform_matrix": pose.tolist(),
                "w": w_out,
                "h": h_out,
                "fl_x": fl_x,
                "fl_y": fl_y,
                "cx": cx,
                "cy": cy
            }
            transforms["frames"].append(frame_entry)

        with open(workspace / "transforms.json", "w") as f:
            json.dump(transforms, f, indent=4)
        logger.info(f"âœ… Saved transforms.json with {len(poses)} frames.")

        # B. ä¿å­˜ç¨€ç–ç‚¹äº‘ (åŠ é€Ÿ Step 2 åˆå§‹åŒ–)
        if cloud is not None:
            # éœ€è¦è½¬ä¸º open3d æˆ– plyfile ä¿å­˜
            # è¿™é‡Œç®€å•å¤ç”¨ MASt3RWrapper çš„ save_results é€»è¾‘éƒ¨åˆ†
            mast3r.save_results(workspace / "sparse_recon", poses, cloud)
            # ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¿å­˜ä¸€ä»½æ ¹ç›®å½•çš„ ply
            import open3d as o3d
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(cloud)
            o3d.io.write_point_cloud(str(workspace / "sparse_pc.ply"), pcd)
            logger.info("âœ… Saved sparse_pc.ply")

    else:
        logger.error("âŒ MASt3R failed to reconstruct poses.")

    # -----------------------------------------------------
    # 8. æœºå™¨äººé…ç½®å¤åˆ¶
    # -----------------------------------------------------
    if robot_config_path.exists():
        with open(robot_config_path) as f:
            data = json.load(f)
        with open(workspace / "align_pose.json", 'w') as f:
            json.dump(data, f)
        logger.info("âœ… Robot config copied.")

    logger.info(f"ğŸ‰ Step 1 Pipeline Finished. All assets in: {workspace}")

if __name__ == "__main__":
    run_step1()