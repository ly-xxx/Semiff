import argparse
import json
import numpy as np
import logging
import cv2
import subprocess
import sys
import pandas as pd
import warnings
from pathlib import Path
from tqdm import tqdm
from omegaconf import OmegaConf, open_dict

warnings.filterwarnings("ignore")

# ==================== 1. è·¯å¾„é…ç½® ====================
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(PROJECT_ROOT / "src"))
from semiff.core.workspace import WorkspaceManager

try:
    from semiff.perception.sam2_wrapper import SAM2Wrapper
except ImportError:
    SAM2Wrapper = None
try:
    from semiff.perception.mast3r_wrapper import MASt3RWrapper
except ImportError:
    MASt3RWrapper = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Step1")

# ==================== è¾…åŠ©å‡½æ•° ====================
def get_video_rotation(video_path):
    """
    è·å–è§†é¢‘çš„æ—‹è½¬ Metadataã€‚
    æ³¨æ„ï¼šè¿™åªæ˜¯ Metadataï¼ŒOpenCV è¯»å–æ—¶å¯èƒ½ä¼šè‡ªåŠ¨åº”ç”¨è¿™ä¸ªæ—‹è½¬ï¼Œä¹Ÿå¯èƒ½ä¸ä¼šã€‚
    """
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', str(video_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0: return None, False
        data = json.loads(result.stdout)
        video_stream = next((s for s in data.get('streams', []) if s['codec_type'] == 'video'), None)
        if not video_stream: return None, False
        rotate = int(video_stream.get('tags', {}).get('rotate', 0))

        if rotate != 0:
            logger.info(f"ğŸ•µï¸ Metadata Rotation Tag: {rotate}Â°")

        if rotate == 90: return cv2.ROTATE_90_CLOCKWISE, True
        elif rotate == 180: return cv2.ROTATE_180, False
        elif rotate == 270: return cv2.ROTATE_90_COUNTERCLOCKWISE, True
        elif rotate == -90: return cv2.ROTATE_90_COUNTERCLOCKWISE, True
        else: return None, False
    except: return None, False

class FFmpegWriter:
    def __init__(self, filename, width, height, fps):
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        if width % 2 != 0: width -= 1
        if height % 2 != 0: height -= 1
        self.cmd = [
            'ffmpeg', '-y', '-f', 'rawvideo', '-vcodec', 'rawvideo',
            '-s', f'{width}x{height}', '-pix_fmt', 'bgr24', '-r', f'{fps}',
            '-i', '-', '-c:v', 'libx264', '-pix_fmt', 'yuv420p',
            '-preset', 'fast', '-crf', '23', str(filename)
        ]
        self.process = subprocess.Popen(self.cmd, stdin=subprocess.PIPE, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)

    def write(self, frame):
        try:
            h, w = frame.shape[:2]
            target_str = self.cmd[7]
            target_w, target_h = int(target_str.split('x')[0]), int(target_str.split('x')[1])
            if w != target_w or h != target_h: frame = cv2.resize(frame, (target_w, target_h))
            self.process.stdin.write(frame.tobytes())
        except: pass

    def release(self):
        if self.process:
            self.process.stdin.close()
            self.process.wait()

# ==================== ä¸»æµç¨‹ ====================
def run_step1():
    base_config_path = PROJECT_ROOT / "configs" / "base_config.yaml"
    base_cfg = OmegaConf.load(base_config_path)

    workspace_mode = base_cfg.pipeline.get("mode", "auto")
    root_dir = base_cfg.data.get("root_dir", "data/example_01")
    video_path_rel = base_cfg.data.get("video_path", "video.mp4")

    dataset_dir = Path(root_dir) if Path(root_dir).is_absolute() else PROJECT_ROOT / root_dir
    video_path = dataset_dir / video_path_rel

    ws_mgr = WorkspaceManager(str(base_config_path))
    workspace = ws_mgr.resolve(mode=workspace_mode)
    logger.info(f"ğŸ“‚ Workspace: {workspace}")

    runtime_cfg_path = workspace / "runtime_config.yaml"
    cfg = OmegaConf.merge(OmegaConf.load(runtime_cfg_path), base_cfg) if runtime_cfg_path.exists() else base_cfg
    OmegaConf.save(cfg, runtime_cfg_path)

    ENABLE_SAM2 = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_sam2", True)
    ENABLE_MAST3R = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_mast3r", True)

    mask_obj_dir = workspace / "masks_object"
    mask_robot_dir = workspace / "masks_robot"
    images_dir = workspace / "images"
    for d in [mask_obj_dir, mask_robot_dir, images_dir]: d.mkdir(exist_ok=True)

    # 1. é¢„è¯»è§†é¢‘ä¿¡æ¯
    rotate_code, is_vertical_meta = get_video_rotation(video_path)

    # 2. è¯»å–ç¬¬ä¸€å¸§æ¥å†³å®šæ˜¯å¦éœ€è¦æ‰‹åŠ¨æ—‹è½¬
    # (è¿™æ˜¯é’ˆå¯¹ä½ çš„ç¯å¢ƒåšçš„ Robust Check)
    temp_cap = cv2.VideoCapture(str(video_path))
    ret, temp_frame = temp_cap.read()
    temp_cap.release()
    if not ret: raise RuntimeError(f"Cannot read video: {video_path}")

    h_raw, w_raw = temp_frame.shape[:2]

    # === æ™ºèƒ½æ—‹è½¬å†³ç­– ===
    need_manual_rotate = False

    # å¦‚æœ Metadata è¯´å®ƒæ˜¯ç«–å± (90/270åº¦)ï¼Œä½†è¯»å‡ºæ¥çš„å®½ > é«˜ (æ¨ªå±)
    # è¯´æ˜ OpenCV æ²¡æœ‰è‡ªåŠ¨æ—‹è½¬ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨è½¬
    if is_vertical_meta and w_raw > h_raw:
        need_manual_rotate = True
        logger.info(f"ğŸ”„ Manual Rotation Required: Metadata says Vertical, but Raw is {w_raw}x{h_raw}")
    else:
        # å¦åˆ™ (Metadataæ²¡è¯´è¦è½¬ï¼Œæˆ–è€… Metadataè¯´äº†è¦è½¬ä¸”OpenCVå·²ç»è½¬æˆäº†ç«–å±)
        need_manual_rotate = False
        logger.info(f"âœ… No Manual Rotation Needed. Raw frame is naturally {w_raw}x{h_raw}")
        # å¦‚æœå·²ç»è‡ªåŠ¨è½¬æ­£äº†ï¼Œæ¸…é™¤ rotate_code é˜²æ­¢åç»­é€»è¾‘è¯¯åˆ¤
        if w_raw < h_raw:
            rotate_code = None

    # æœ€ç»ˆè¾“å‡ºå°ºå¯¸
    if need_manual_rotate:
        # äº¤æ¢å®½é«˜
        w_out, h_out = h_raw, w_raw
    else:
        # ä¿æŒåŸæ ·
        w_out, h_out = w_raw, h_raw

    logger.info(f"ğŸ“ Target Dims: {w_out}x{h_out}")
    rgb_frames_buffer = []

    # === Phase A: SAM 2 ===
    if ENABLE_SAM2:
        logger.info("ğŸ¨ [SAM2] Starting Segmentation...")
        # æ³¨æ„ï¼šæˆ‘ä»¬å°† 'rotate_code' ä¼ ç»™ SAM2 ä»…ç”¨äºå®ƒå†…éƒ¨é€»è¾‘
        # ä½†æ—¢ç„¶æˆ‘ä»¬å‘ç°ç¯å¢ƒä¼šè‡ªåŠ¨æ—‹è½¬ï¼Œè¿™é‡Œä¼  None ä¹Ÿæ˜¯å®‰å…¨çš„ï¼Œ
        # æˆ–è€…åªåœ¨ need_manual_rotate ä¸º True æ—¶ä¼ ã€‚

        eff_rotate_code = rotate_code if need_manual_rotate else None

        with open_dict(cfg):
            if 'pipeline' not in cfg: cfg.pipeline = {}
            # åªæœ‰éœ€è¦æ‰‹åŠ¨è½¬çš„æ—¶å€™ï¼Œæ‰å‘Šè¯‰ SAM2 å»å¤„ç†æ—‹è½¬
            if eff_rotate_code is not None:
                cfg.pipeline.input_rotate_code = int(eff_rotate_code)
            else:
                cfg.pipeline.input_rotate_code = None

        sam2 = SAM2Wrapper(cfg)

        if sam2.predictor:
            vis_writer = FFmpegWriter(workspace / "segmentation_vis.mp4", w_out, h_out, 30)
            generator = sam2.run_generator(str(video_path), output_dir=workspace)
            cap_read = cv2.VideoCapture(str(video_path))
            current_idx = 0

            try:
                # è·å–æ€»å¸§æ•°ç”¨äºè¿›åº¦æ¡
                total_frames = int(cap_read.get(cv2.CAP_PROP_FRAME_COUNT))
                pbar = tqdm(total=total_frames, desc="Processing")

                for result in generator:
                    if result.get("status") == "cancelled": break

                    frame_idx = result["frame_idx"]
                    all_masks = result["masks"]

                    # åŒæ­¥è¯»å–è§†é¢‘å¸§
                    while current_idx <= frame_idx:
                        ret, raw_frame = cap_read.read()
                        current_idx += 1
                    if not ret: break

                    # === è¿™é‡Œçš„ frame_upright æ˜¯ç»™æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ (MASt3R, Vis) ç”¨çš„æ ‡å‡†å¸§ ===
                    if need_manual_rotate and rotate_code is not None:
                        frame_upright = cv2.rotate(raw_frame, rotate_code)
                    else:
                        frame_upright = raw_frame

                    # ä¿å­˜ RGB å¸§
                    cv2.imwrite(str(images_dir / f"{frame_idx:05d}.png"), frame_upright)
                    rgb_frames_buffer.append(cv2.cvtColor(frame_upright, cv2.COLOR_BGR2RGB))

                    # å¤„ç† Mask å’Œå¯è§†åŒ–
                    vis_frame = frame_upright.copy()

                    for obj_id, mask_in in all_masks.items():
                        mask_u8 = (mask_in * 255).astype(np.uint8)

                        # æ£€æŸ¥ Mask å°ºå¯¸æ˜¯å¦éœ€è¦è°ƒæ•´ (é€šå¸¸ SAM2 å†…éƒ¨å¦‚æœä¸è½¬ï¼Œè¿™é‡Œ mask ä¹Ÿæ˜¯ raw å°ºå¯¸)
                        mh, mw = mask_u8.shape[:2]
                        th, tw = frame_upright.shape[:2]

                        if mh != th or mw != tw:
                            # åªæœ‰åœ¨å°ºå¯¸ä¸åŒ¹é…æ—¶æ‰ Resize/Rotate
                            mask_upright = cv2.resize(mask_u8, (tw, th), interpolation=cv2.INTER_NEAREST)
                        else:
                            mask_upright = mask_u8

                        filename = f"{frame_idx:05d}.png"
                        target_dir = mask_obj_dir if obj_id == 1 else mask_robot_dir
                        cv2.imwrite(str(target_dir / filename), mask_upright)

                        # å¯è§†åŒ–å åŠ 
                        color_vis = (0, 0, 255) if obj_id == 1 else (255, 0, 0)
                        mask_bool = mask_upright > 128
                        if mask_bool.any():
                            # ç®€æ˜“åŠé€æ˜å åŠ 
                            overlay = vis_frame.copy()
                            overlay[mask_bool] = color_vis
                            cv2.addWeighted(overlay, 0.4, vis_frame, 0.6, 0, vis_frame)

                    vis_writer.write(vis_frame)
                    pbar.update(1)
                pbar.close()
            finally:
                vis_writer.release()
                cap_read.release()

    else:
        # =========================================================
        # ğŸ†• æ–°å¢é€»è¾‘ï¼šå¦‚æœ SAM2 è¢«ç¦ç”¨ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨è¯»å–è§†é¢‘ï¼
        # =========================================================
        logger.info("ğŸ¥ SAM2 disabled. Reading video frames manually for MASt3R...")

        cap_read = cv2.VideoCapture(str(video_path))
        total_frames = int(cap_read.get(cv2.CAP_PROP_FRAME_COUNT))
        pbar = tqdm(total=total_frames, desc="Reading Frames")
        frame_idx = 0

        while True:
            ret, raw_frame = cap_read.read()
            if not ret: break

            # === æ ¸å¿ƒï¼šåº”ç”¨ä¹‹å‰æ£€æµ‹åˆ°çš„æ—‹è½¬é€»è¾‘ ===
            if need_manual_rotate and rotate_code is not None:
                frame_upright = cv2.rotate(raw_frame, rotate_code)
            else:
                frame_upright = raw_frame

            # 1. ä¿å­˜åˆ° Buffer ç»™ MASt3R
            rgb_frames_buffer.append(cv2.cvtColor(frame_upright, cv2.COLOR_BGR2RGB))

            # 2. (å¯é€‰) ä¿å­˜å›¾ç‰‡åˆ°ç£ç›˜ï¼Œæ–¹ä¾¿ä½ æ£€æŸ¥æ—‹è½¬æ˜¯å¦æ­£ç¡®
            # æ—¢ç„¶æ˜¯ Debug é˜¶æ®µï¼Œå¼ºçƒˆå»ºè®®ä¿å­˜ä¸€ä¸‹ï¼Œç¡®è®¤å›¾ç‰‡æ˜¯ä¸æ˜¯æ­£çš„
            cv2.imwrite(str(images_dir / f"{frame_idx:05d}.png"), frame_upright)

            frame_idx += 1
            pbar.update(1)

        pbar.close()
        cap_read.release()
        logger.info(f"âœ… Loaded {len(rgb_frames_buffer)} frames.")

    # === Phase B: MASt3R ===
    # (ç¡®ä¿è¿™é‡Œåˆ¤æ–­äº† buffer ä¸ä¸ºç©º)
    if ENABLE_MAST3R and MASt3RWrapper is not None and len(rgb_frames_buffer) > 0:
        logger.info(f"ğŸ§  [MASt3R] Starting Geometry Reconstruction with {len(rgb_frames_buffer)} frames...")
        mast3r = MASt3RWrapper(device="cuda")

        # è¿™é‡Œçš„ rgb_frames_buffer å·²ç»æ˜¯ æ­£ç¡®æœå‘ (Upright) çš„äº†
        # ä¸éœ€è¦å†ä¼  rotate_codeï¼Œç›´æ¥å–‚è¿›å»
        # åˆ›å»ºè°ƒè¯•ç›®å½•
        debug_dir = workspace / "debug_mast3r"
        debug_dir.mkdir(exist_ok=True)

        poses, cloud = mast3r.run(
            frames=rgb_frames_buffer,
            keyframe_interval=3,   # é™ä½é—´éš”ä¿è¯é«˜é‡å ç‡
            debug_dir=debug_dir    # å¯ç”¨è°ƒè¯•å¯è§†åŒ–
        )

        # ä¿å­˜ç»“æœ
        np.save(workspace / "camera_poses.npy", poses)
        np.save(workspace / "sparse_cloud.npy", cloud)

        # ğŸ†• ä¿å­˜å½©è‰² PLY
        if cloud.shape[0] > 0:
            ply_path = workspace / "sparse_cloud.ply"

            # åˆ†ç¦»åæ ‡å’Œé¢œè‰²
            xyz = cloud[:, :3]
            rgb = cloud[:, 3:].astype(np.uint8) # è½¬å›æ•´æ•°ä»¥ä¾¿å†™å…¥

            header = (
                "ply\n"
                "format ascii 1.0\n"
                f"element vertex {len(cloud)}\n"
                "property float x\n"
                "property float y\n"
                "property float z\n"
                "property uchar red\n"
                "property uchar green\n"
                "property uchar blue\n"
                "end_header\n"
            )

            with open(ply_path, "w") as f:
                f.write(header)
                for p, c in zip(xyz, rgb):
                    # å†™å…¥: X Y Z R G B
                    f.write(f"{p[0]:.4f} {p[1]:.4f} {p[2]:.4f} {int(c[0])} {int(c[1])} {int(c[2])}\n")

            logger.info(f"âœ… Saved COLOR point cloud to {ply_path}")
            logger.info(f"ğŸ–¼ï¸ Check debug images in {debug_dir}")
    else:
        if len(rgb_frames_buffer) == 0:
            logger.error("âŒ No frames loaded! Cannot run MASt3R.")

if __name__ == "__main__":
    run_step1()