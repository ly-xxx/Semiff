import argparse
import json
import numpy as np
import logging
import cv2
import subprocess
import sys
import pandas as pd
import warnings
from pathlib import Path
from tqdm import tqdm
from omegaconf import OmegaConf, open_dict

warnings.filterwarnings("ignore")

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.append(str(PROJECT_ROOT / "src"))
from semiff.core.workspace import WorkspaceManager

try:
    from semiff.solvers.sam2_wrapper import SAM2Wrapper
except ImportError:
    SAM2Wrapper = None
try:
    from semiff.solvers.mast3r_wrapper import MASt3RWrapper
except ImportError:
    MASt3RWrapper = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Step1")

# ... (è¾…åŠ©å‡½æ•° get_video_rotation å’Œ FFmpegWriter ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çœç¯‡å¹…) ...

def get_video_rotation(video_path):
    # (ä¿æŒåŸæ ·)
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', str(video_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0: return None, False
        data = json.loads(result.stdout)
        video_stream = next((s for s in data.get('streams', []) if s['codec_type'] == 'video'), None)
        if not video_stream: return None, False
        rotate = int(video_stream.get('tags', {}).get('rotate', 0))
        if rotate != 0: logger.info(f"ğŸ•µï¸ Metadata Rotation Tag: {rotate}Â°")
        if rotate == 90: return cv2.ROTATE_90_CLOCKWISE, True
        elif rotate == 180: return cv2.ROTATE_180, False
        elif rotate == 270: return cv2.ROTATE_90_COUNTERCLOCKWISE, True
        elif rotate == -90: return cv2.ROTATE_90_COUNTERCLOCKWISE, True
        else: return None, False
    except: return None, False

def run_step1():
    base_config_path = PROJECT_ROOT / "configs" / "base_config.yaml"
    base_cfg = OmegaConf.load(base_config_path)

    workspace_mode = base_cfg.pipeline.get("mode", "auto")
    root_dir = base_cfg.data.get("root_dir", "data/example_01")
    video_path_rel = base_cfg.data.get("video_path", "video.mp4")

    dataset_dir = Path(root_dir) if Path(root_dir).is_absolute() else PROJECT_ROOT / root_dir
    video_path = dataset_dir / video_path_rel

    ws_mgr = WorkspaceManager(str(base_config_path))
    workspace = ws_mgr.resolve(mode=workspace_mode)
    logger.info(f"ğŸ“‚ Workspace: {workspace}")

    runtime_cfg_path = workspace / "runtime_config.yaml"
    cfg = OmegaConf.merge(OmegaConf.load(runtime_cfg_path), base_cfg) if runtime_cfg_path.exists() else base_cfg
    OmegaConf.save(cfg, runtime_cfg_path)

    ENABLE_SAM2 = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_sam2", True)
    ENABLE_MAST3R = cfg.pipeline.get("steps", {}).get("step1", {}).get("enable_mast3r", True)

    mask_obj_dir = workspace / "masks_object"
    mask_robot_dir = workspace / "masks_robot"
    images_dir = workspace / "images"
    for d in [mask_obj_dir, mask_robot_dir, images_dir]: d.mkdir(exist_ok=True)

    rotate_code, is_vertical_meta = get_video_rotation(video_path)
    temp_cap = cv2.VideoCapture(str(video_path))
    ret, temp_frame = temp_cap.read()
    temp_cap.release()
    if not ret: raise RuntimeError(f"Cannot read video: {video_path}")
    h_raw, w_raw = temp_frame.shape[:2]

    need_manual_rotate = False
    if is_vertical_meta and w_raw > h_raw:
        need_manual_rotate = True
        logger.info(f"ğŸ”„ Manual Rotation Required: Metadata says Vertical, but Raw is {w_raw}x{h_raw}")
    else:
        logger.info(f"âœ… No Manual Rotation Needed. Raw frame is naturally {w_raw}x{h_raw}")
        if w_raw < h_raw: rotate_code = None

    if need_manual_rotate: w_out, h_out = h_raw, w_raw
    else: w_out, h_out = w_raw, h_raw
    logger.info(f"ğŸ“ Target Dims: {w_out}x{h_out}")

    rgb_frames_buffer = []
    masks_buffer = [] # å­˜å‚¨å¯¹åº”å¸§çš„ Robot Mask

    # === Phase A: SAM 2 ===
    if ENABLE_SAM2:
        logger.info("ğŸ¨ [SAM2] Starting Segmentation...")
        eff_rotate_code = rotate_code if need_manual_rotate else None
        
        with open_dict(cfg):
            if 'pipeline' not in cfg: cfg.pipeline = {}
            cfg.pipeline.input_rotate_code = int(eff_rotate_code) if eff_rotate_code is not None else None

        sam2 = SAM2Wrapper(cfg)

        if sam2.predictor:
            # è¿™é‡Œ vis_writer ç›¸å…³çš„ä»£ç æˆ‘ç•¥å¾®ç²¾ç®€ï¼Œé‡ç‚¹åœ¨ mask æå–
            generator = sam2.run_generator(str(video_path), output_dir=workspace)
            cap_read = cv2.VideoCapture(str(video_path))
            current_idx = 0

            try:
                total_frames = int(cap_read.get(cv2.CAP_PROP_FRAME_COUNT))
                pbar = tqdm(total=total_frames, desc="Processing")

                for result in generator:
                    if result.get("status") == "cancelled": break
                    frame_idx = result["frame_idx"]
                    all_masks = result["masks"] # Dict {obj_id: mask}

                    while current_idx <= frame_idx:
                        ret, raw_frame = cap_read.read()
                        current_idx += 1
                    if not ret: break

                    if need_manual_rotate and rotate_code is not None:
                        frame_upright = cv2.rotate(raw_frame, rotate_code)
                    else:
                        frame_upright = raw_frame

                    cv2.imwrite(str(images_dir / f"{frame_idx:05d}.png"), frame_upright)
                    rgb_frames_buffer.append(cv2.cvtColor(frame_upright, cv2.COLOR_BGR2RGB))

                    # ğŸ”¥ Mask å¤„ç†é€»è¾‘ï¼šåªæå– Robot (ID=2)ï¼Œæˆ–è€…åˆå¹¶æ‰€æœ‰å‰æ™¯
                    # å‡è®¾ ID 2 æ˜¯æœºæ¢°è‡‚
                    robot_mask = np.zeros((h_out, w_out), dtype=np.uint8)
                    
                    if 2 in all_masks:
                        m = (all_masks[2] * 255).astype(np.uint8)
                        # Resize ä¿æŠ¤
                        if m.shape[:2] != (h_out, w_out):
                            m = cv2.resize(m, (w_out, h_out), interpolation=cv2.INTER_NEAREST)
                        robot_mask = m
                        # ä¿å­˜ä¸€ä»½åˆ°ç£ç›˜
                        cv2.imwrite(str(mask_robot_dir / f"{frame_idx:05d}.png"), robot_mask)
                    
                    masks_buffer.append(robot_mask) # å­˜å…¥ Buffer
                    pbar.update(1)
                pbar.close()
            finally:
                cap_read.release()
    else:
        # Manual Mode
        # ... (ç®€ç•¥ï¼ŒåŒå‰) ...
        pass

    # === Phase B: MASt3R ===
    if ENABLE_MAST3R and MASt3RWrapper is not None and len(rgb_frames_buffer) > 0:
        logger.info(f"ğŸ§  [MASt3R] Reconstruction with {len(rgb_frames_buffer)} frames...")
        mast3r = MASt3RWrapper(device="cuda")
        debug_dir = workspace / "debug_mast3r"
        debug_dir.mkdir(exist_ok=True)

        # è¿è¡Œ MASt3Rï¼Œä¼ å…¥ masks_buffer ç”¨äºæ ‡è®°
        # keyframe_interval è®¾ä¸º 2ï¼Œå°½å¯èƒ½å¤šåœ°å–‚æ•°æ®ï¼Œç”± wrapper å†…éƒ¨æ§åˆ¶ 120 å¸§ä¸Šé™
        poses, cloud, intrinsics = mast3r.run(
            frames=rgb_frames_buffer,
            masks=masks_buffer, 
            keyframe_interval=2, 
            debug_dir=debug_dir
        )

        np.save(workspace / "camera_poses.npy", poses)
        np.save(workspace / "sparse_cloud.npy", cloud) # æ³¨æ„ç°åœ¨ cloud æ˜¯ Nx7
        np.save(workspace / "intrinsics.npy", intrinsics)
        
        # ğŸ†• ä¿å­˜å¸¦ Label çš„ PLY
        if cloud.shape[0] > 0:
            ply_path = workspace / "sparse_cloud.ply"
            
            # cloud: [X, Y, Z, R, G, B, Label]
            xyz = cloud[:, :3]
            rgb = cloud[:, 3:6].astype(np.uint8)
            lbl = cloud[:, 6].astype(np.uint8)

            # è‡ªå®šä¹‰ Headerï¼Œå¢åŠ  'label' å±æ€§
            header = (
                "ply\n"
                "format ascii 1.0\n"
                f"element vertex {len(cloud)}\n"
                "property float x\n"
                "property float y\n"
                "property float z\n"
                "property uchar red\n"
                "property uchar green\n"
                "property uchar blue\n"
                "property uchar label\n"  # ğŸ”¥ æ–°å¢å±æ€§
                "end_header\n"
            )

            with open(ply_path, "w") as f:
                f.write(header)
                # é€è¡Œå†™å…¥
                for p, c, l in zip(xyz, rgb, lbl):
                    f.write(f"{p[0]:.4f} {p[1]:.4f} {p[2]:.4f} {int(c[0])} {int(c[1])} {int(c[2])} {int(l)}\n")

            logger.info(f"âœ… Saved LABELED point cloud to {ply_path}")
            logger.info("â„¹ï¸  Use 'label' scalar field in CloudCompare/MeshLab to isolate robot.")
    else:
        if len(rgb_frames_buffer) == 0: logger.error("âŒ No frames loaded!")

if __name__ == "__main__":
    run_step1()