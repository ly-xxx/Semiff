# Semiff: Kinematic-Anchored Sim2Real Asset Construction

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)]()

**Semiff** (Semantic & Diffuser) æ˜¯ä¸€ä¸ªåŸºäºå•ç›®è§†é¢‘çš„æœºå™¨äººåœºæ™¯æ•°å­—åŒ–é‡å»ºæµæ°´çº¿ã€‚
å…¶æ ¸å¿ƒç†å¿µæ˜¯ **"Physics as Anchor"**ï¼šåˆ©ç”¨æœºå™¨äººè‡ªèº«çš„ç²¾ç¡®è¿åŠ¨å­¦æ¨¡å‹ï¼ˆURDFï¼‰ä½œä¸ºå‡ ä½•çœŸå€¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“æŠ€æœ¯æ¶ˆé™¤å•ç›®è§†è§‰é‡å»ºï¼ˆMASt3R/3DGSï¼‰ä¸­çš„å°ºåº¦äºŒä¹‰æ€§å’Œåæ ‡ç³»æ¼‚ç§»ã€‚

---

## ğŸ— Pipeline æ¶æ„

æœ¬é¡¹ç›®é€šè¿‡å››ä¸ªçº¿æ€§æ­¥éª¤å°†å•ç›® RGB è§†é¢‘è½¬åŒ–ä¸ºå¯ç‰©ç†ä»¿çœŸçš„ Digital Twin èµ„äº§ï¼š

### Step 1: Data Solver (è§†è§‰è§£ç®—)
> *Status: âœ… Completed*
* **ç›®æ ‡**: ä»éç»“æ„åŒ–è§†é¢‘ä¸­æå–å‡ ä½•ä¸è¯­ä¹‰ä¿¡æ¯ã€‚
* **æ ¸å¿ƒæŠ€æœ¯**:
    * **MASt3R**: æå–ç¨ å¯† 3D ç‚¹äº‘ä¸ç›¸æœºä½å§¿ (Camera Poses)ã€‚
    * **SAM 2.1**: åˆ†å‰²æœºæ¢°è‡‚ (Robot) ä¸ç›®æ ‡ç‰©ä½“ (Object) çš„ 2D æ©ç ã€‚
* **è¾“å‡º**: ç¨€ç–ç‚¹äº‘ã€ç›¸æœºè½¨è¿¹ã€è¯­ä¹‰æ©ç åºåˆ—ã€‚

### Step 2: Self-Calibration (è¿åŠ¨å­¦è‡ªæ ‡å®š)
> *Status: ğŸš§ In Progress*
* **ç›®æ ‡**: è§£å†³ Sim2Real çš„ "Scale Ambiguity" é—®é¢˜ã€‚
* **æ ¸å¿ƒåŸç†**:
    * å›ºå®š URDF å‡ ä½•çœŸå€¼ï¼ˆHard Constraintï¼‰ã€‚
    * ä¼˜åŒ–è§†è§‰ä¸–ç•Œçš„ `Scale` å’Œ `Base_Transform`ã€‚
    * Loss: æ¸²æŸ“çš„ URDF æŠ•å½± vs SAM2 åˆ†å‰²æ©ç  (IoU Loss)ã€‚
* **å·¥å…·**: `nvdiffrast`, `pytorch_kinematics`.

### Step 3: Global Reconstruction (å…¨å±€é‡å»º)
> *Status: ğŸ“… Planned*
* **ç›®æ ‡**: è®­ç»ƒé«˜è´¨é‡é™æ€ 3D Gaussian Splatting (3DGS) åœºã€‚
* **ç­–ç•¥**: ä½¿ç”¨ Step 2 çŸ«æ­£åçš„å°ºåº¦æˆ–ä½å§¿è¿›è¡Œè®­ç»ƒï¼Œç¡®ä¿åœºæ™¯å…·æœ‰çœŸå®çš„ç‰©ç†åº¦é‡å•ä½ã€‚

### Step 4: Asset Decomposition (èµ„äº§æ‹†è§£)
> *Status: ğŸ“… Planned*
* **ç›®æ ‡**: ç”Ÿæˆ Warp/Isaac Gym å¯ç”¨çš„èµ„äº§ã€‚
* **é€»è¾‘**: åŸºäºå¯¹é½åçš„ URDF è¿›è¡Œç©ºé—´æŸ¥è¯¢ï¼ˆGeometric Queryï¼‰ï¼Œå°† 3DGS ç‚¹äº‘åˆ‡å‰²ä¸º Robotã€Object å’Œ Backgroundï¼Œå¹¶å®Œæˆéª¨éª¼ç»‘å®šã€‚

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
semiff/
â”œâ”€â”€ configs/                # Hydra/OmegaConf é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ base_config.yaml    # åŸºç¡€é…ç½®
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                   # è¾“å…¥æ•°æ®ç›®å½•
â”‚   â””â”€â”€ example_01/         # ç¤ºä¾‹æ•°æ®é›†
â”‚       â”œâ”€â”€ video.mp4       # åŸå§‹è§†é¢‘
â”‚       â”œâ”€â”€ config/         # æœºå™¨äººå…³èŠ‚é…ç½®
â”‚       â””â”€â”€ robot/          # URDF èµ„äº§
â”œâ”€â”€ outputs/                # å®éªŒè¾“å‡º (è‡ªåŠ¨æŒ‰æ—¶é—´æˆ³ç”Ÿæˆ)
â”‚   â””â”€â”€ 20260106_210039/    # æŸæ¬¡è¿è¡Œç»“æœ
â”‚       â”œâ”€â”€ camera_poses.npy
â”‚       â”œâ”€â”€ masks_robot/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ src/                    # æ ¸å¿ƒæºç 
â”‚   â””â”€â”€ semiff/
â”‚       â”œâ”€â”€ core/           # æ¸²æŸ“ã€IOã€é…ç½®ç®¡ç†
â”‚       â”œâ”€â”€ perception/     # SAM2, MASt3R å°è£…
â”‚       â””â”€â”€ utils/          # æ•°å­¦å·¥å…·åº“
â”œâ”€â”€ tools/                  # æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ step1_preprocess.py # [Done] æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ step2_calibrate.py  # [Todo] è‡ªæ ‡å®šè„šæœ¬
â””â”€â”€ main.py                 # ç»Ÿä¸€å…¥å£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒä¾èµ–
è¯·ç¡®ä¿å®‰è£…å¸¦æœ‰ OpenGL æ”¯æŒçš„ NVIDIA é©±åŠ¨ (ç”¨äº nvdiffrast)ã€‚

```bash
pip install -r requirements.txt
# é¢å¤–å®‰è£… nvdiffrast
git clone https://github.com/NVlabs/nvdiffrast
pip install ./nvdiffrast
```

### è¿è¡Œ Step 1: é¢„å¤„ç†
```bash
python tools/step1_preprocess.py \
    data_dir=data/example_01 \
    output_dir=outputs/new
```

### è¿è¡Œ Step 2: è‡ªæ ‡å®š (Coming Soon)
```bash
python tools/step2_calibrate.py \
    workspace=outputs/20260106_210039 \
    robot_urdf=data/example_01/robot/rllab_xarm/xarm6_robot.urdf
```

## ğŸ“ è´¡çŒ®æŒ‡å—

* è§†è§‰åæ ‡ç³»é‡‡ç”¨ OpenCV æ ‡å‡† (Right-Down-Forward)ã€‚
* ç‰©ç†åæ ‡ç³»é‡‡ç”¨ URDF æ ‡å‡†ã€‚
* æäº¤ä»£ç å‰è¯·è¿è¡Œ tests/ ä¸‹çš„å•å…ƒæµ‹è¯•ã€‚

---

### è¯„ä¼°ä¸ä¸‹ä¸€æ­¥

1.  **å…³äº `render.py` çš„ä¿®æ­£å»ºè®®**ï¼š
    * ç›®å‰çš„ `render.py` ä¸­ `build_projection_matrix` ç”Ÿæˆçš„æ˜¯ NDC æŠ•å½±ï¼Œä½† `render` å‡½æ•°ä¼¼ä¹æ²¡æœ‰æ˜¾å¼å¤„ç† World-to-Camera (View Matrix) çš„å˜æ¢ã€‚
    * åœ¨ç¼–å†™ Step 2 ä»£ç æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ä¼ å…¥ `vertices` ç»™ `render` å‡½æ•°ä¹‹å‰ï¼Œå…ˆæ‰‹åŠ¨ç”¨ `cam_poses` (Extrinsics) å°†å…¶å˜æ¢åˆ°ç›¸æœºåæ ‡ç³»ã€‚æˆ–è€…ä¿®æ”¹ `render.py` è®©å…¶æ¥å— `T_view`ã€‚æˆ‘å»ºè®®åœ¨ Step 2 çš„å¤–éƒ¨é€»è¾‘ä¸­å¤„ç†è¿™ä¸ªå˜æ¢ï¼Œä¿æŒ `render.py` çš„çº¯ç²¹æ€§ï¼ˆåªè´Ÿè´£ Projection + Rasterizationï¼‰ã€‚

2.  **å…³äºæœºå™¨äººå§¿æ€**ï¼š
    * æ—¢ç„¶æä¾›äº† `align_pose.json` ä¸”æœºå™¨äººæ˜¯é™æ­¢çš„ï¼ŒStep 2 ä»£ç å°†è¯»å–è¿™ä¸ª JSONï¼Œå¯¹æ‰€æœ‰æ—¶åˆ» $t$ ä½¿ç”¨ç›¸åŒçš„å…³èŠ‚è§’ $q$ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç®€åŒ–ã€‚