"""
MASt3R Wrapper: End-to-End Image Matching & Reconstruction
"""

import torch
import numpy as np
import open3d as o3d
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm

# å‡è®¾ MASt3R å·²å®‰è£…åœ¨ç¯å¢ƒä¸­
import sys
from pathlib import Path

# æ·»åŠ  MASt3R åˆ°è·¯å¾„
mast3r_path = Path(__file__).parents[3] / "third_party" / "mast3r"
if mast3r_path.exists():
    sys.path.insert(0, str(mast3r_path))

try:
    from mast3r.model import AsymmetricMASt3R
    from mast3r.cloud_opt.sparse_ga import GlobalAlignment
except ImportError:
    pass # å…è®¸åœ¨æ—  MASt3R ç¯å¢ƒä¸‹å¯¼å…¥ç±»å®šä¹‰ç”¨äºæµ‹è¯•

from ..core.logger import get_logger

logger = get_logger(__name__)

class MASt3RWrapper:
    def __init__(self, device: str = "cuda"):
        self.device = device
        self.model = self._load_model()

    def _load_model(self):
        try:
            # å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™è¯´æ˜ç¯å¢ƒæœªå‡†å¤‡å¥½
            from mast3r.model import AsymmetricMASt3R

            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„
            model_path = Path(__file__).parents[3] / "checkpoints" / "MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth"
            logger.info(f"Loading MASt3R model from: {model_path}")

            if not model_path.exists():
                raise FileNotFoundError(f"Model file not found: {model_path}")

            model = AsymmetricMASt3R.from_pretrained(str(model_path)).to(self.device)
            model.eval()
            return model
        except Exception as e:
            logger.warning(f"MASt3R load failed ({e}). Running in mock mode.")
            return None

    def preprocess_image(self, image: np.ndarray) -> torch.Tensor:
        """RGB numpy [H,W,3] -> Tensor [1,3,512,512]"""
        # ç®€å•çš„é¢„å¤„ç†ï¼Œå®é™…åº”åŒ…å« resize/padding åˆ° 512x512
        import torchvision.transforms as T
        transform = T.Compose([
            T.ToPILImage(),
            T.Resize((512, 512)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        return transform(image).unsqueeze(0).to(self.device)

    def run(self, frames: List[np.ndarray], keyframe_interval: int = 15, rotate_code: Optional[int] = None) -> Tuple[List[np.ndarray], np.ndarray]:
        """
        è¿è¡Œé‡å»ºæµæ°´çº¿
        Args:
            frames: RGBå¸§åˆ—è¡¨
            keyframe_interval: å…³é”®å¸§é—´éš”
            rotate_code: æ—‹è½¬ä»£ç ï¼ˆä»SAM2ä¼ é€’è¿‡æ¥ï¼Œé¿å…é‡å¤æ£€æµ‹ï¼‰
        """
        # ä½¿ç”¨ä¼ å…¥çš„æ—‹è½¬ä»£ç 
        self.rotate_code = rotate_code
        if self.rotate_code is not None:
            logger.info(f"ğŸ”„ MASt3R: ä½¿ç”¨ä¼ å…¥çš„æ—‹è½¬ä»£ç  (ä»£ç : {self.rotate_code})")
        if self.model is None:
            logger.warning("MASt3R model is missing. Returning mock data.")
            return [np.eye(4) for _ in range(len(frames)//keyframe_interval)], np.random.rand(100, 3)

        # 1. ç¨€ç–é‡‡æ ·
        key_indices = list(range(0, len(frames), keyframe_interval))
        keyframes = [frames[i] for i in key_indices]
        kf_tensors = [self.preprocess_image(f) for f in keyframes]
        n_kf = len(keyframes)

        logger.info(f"Processing {n_kf} keyframes (Interval: {keyframe_interval})...")

        # 2. åŒ¹é…ç­–ç•¥ (Sequential + Skip-1)
        pairs = []
        for i in range(n_kf):
            if i + 1 < n_kf: pairs.append((i, i+1))
            if i + 2 < n_kf: pairs.append((i, i+2)) # å¢åŠ è·¨å¸§åŒ¹é…å¢å¼ºç¨³å®šæ€§

        # 3. æ„å»ºä¼˜åŒ–å›¾
        optimizer = GlobalAlignment(init_mode="mst", device=self.device)
        for i, img_tensor in enumerate(kf_tensors):
            optimizer.add_view(i, img_tensor)

        logger.info(f"Computing matches for {len(pairs)} pairs...")
        with torch.no_grad():
            for idx1, idx2 in tqdm(pairs):
                img1 = kf_tensors[idx1]
                img2 = kf_tensors[idx2]

                res = self.model(img1, img2)

                # æå–ç»“æœ (æ ¹æ® MASt3R API è°ƒæ•´)
                # å‡è®¾ res åŒ…å« 'pts1', 'pts2', 'conf'
                # å®é™… API å¯èƒ½éœ€è¦ model.extract_matches æˆ–ç±»ä¼¼è°ƒç”¨
                # è¿™é‡Œä½¿ç”¨é€šç”¨ç»“æ„
                pts1 = res['pts1']
                pts2 = res['pts2']
                conf = res['conf']

                # è¿‡æ»¤å¹¶æ·»åŠ çº¦æŸ
                mask = conf > 0.90 # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
                if mask.sum() > 50: # è‡³å°‘æœ‰ 50 ä¸ªåŒ¹é…ç‚¹
                    optimizer.add_pair_constraint(idx1, idx2, pts1[mask], pts2[mask], conf[mask])

        # 4. å…¨å±€ä¼˜åŒ–
        logger.info("Running Global Optimization...")
        optimizer.optimize(n_iters=500, lr=0.01)

        # 5. ç»“æœæå–
        poses = optimizer.get_poses() # List[Tensor 4x4]
        cloud = optimizer.get_global_point_cloud() # Tensor [N, 3]

        poses_np = [p.detach().cpu().numpy() for p in poses]
        cloud_np = cloud.detach().cpu().numpy()

        logger.info(f"Reconstruction done. Cloud: {cloud_np.shape}, Poses: {len(poses_np)}")
        return poses_np, cloud_np

    def save_results(self, output_dir: Path, poses: List[np.ndarray], cloud: np.ndarray):
        """ä¿å­˜æ ‡å‡†æ ¼å¼ç»“æœ"""
        output_dir.mkdir(parents=True, exist_ok=True)

        # 1. ä¿å­˜ç‚¹äº‘ (PLY)
        if len(cloud) > 0:
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(cloud)
            o3d.io.write_point_cloud(str(output_dir / "scene.ply"), pcd)

        # 2. ä¿å­˜ç›¸æœº (JSON)
        cameras = {}
        for i, pose in enumerate(poses):
            cameras[i] = pose.tolist()

        with open(output_dir / "cameras.json", "w") as f:
            json.dump(cameras, f, indent=4)

        # 3. ä¿å­˜ Pose NPY (æ–¹ä¾¿è¯»å–)
        np.save(output_dir / "poses.npy", np.array(poses))

        logger.info(f"ğŸ’¾ Results saved to {output_dir}")