"""
æ•°å­¦å·¥å…·å‡½æ•° - åæ ‡å˜æ¢å’Œå‡ ä½•è¿ç®—
æä¾›å¯å¾®åˆ†çš„å‡ ä½•å˜æ¢æ“ä½œ
"""

import torch
import numpy as np
from typing import Union, Tuple


def transform_points(points: torch.Tensor, transform: torch.Tensor) -> torch.Tensor:
    """
    åº”ç”¨å˜æ¢çŸ©é˜µåˆ°ç‚¹é›†

    Args:
        points: (N, 3) æˆ– (B, N, 3) ç‚¹é›†
        transform: (4, 4) æˆ– (B, 4, 4) å˜æ¢çŸ©é˜µ

    Returns:
        å˜æ¢åŽçš„ç‚¹é›†ï¼Œå½¢çŠ¶ä¸Žè¾“å…¥ç›¸åŒ
    """
    if points.dim() == 2 and transform.dim() == 2:
        # å•æ‰¹æ¬¡æƒ…å†µ
        ones = torch.ones(points.shape[0], 1, device=points.device, dtype=points.dtype)
        points_homo = torch.cat([points, ones], dim=1)
        transformed_homo = torch.matmul(points_homo, transform.T)
        return transformed_homo[:, :3]

    elif points.dim() == 3 and transform.dim() == 3:
        # æ‰¹æ¬¡æƒ…å†µ
        B, N, _ = points.shape
        ones = torch.ones(B, N, 1, device=points.device, dtype=points.dtype)
        points_homo = torch.cat([points, ones], dim=2)
        transformed_homo = torch.matmul(points_homo, transform.transpose(1, 2))
        return transformed_homo[:, :, :3]

    else:
        raise ValueError(f"Unsupported tensor dimensions: points {points.shape}, transform {transform.shape}")


def rotation_6d_to_matrix(rot_6d: torch.Tensor) -> torch.Tensor:
    """
    å°†6Dæ—‹è½¬è¡¨ç¤ºè½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ (Zhou et al., "On the Continuity of Rotation Representations in Neural Networks")

    Args:
        rot_6d: (..., 6) 6Dæ—‹è½¬å‚æ•°

    Returns:
        (..., 3, 3) æ—‹è½¬çŸ©é˜µ
    """
    if rot_6d.shape[-1] != 6:
        raise ValueError(f"Expected 6D rotation, got shape {rot_6d.shape}")

    # æå–ä¸¤ä¸ªæ­£äº¤å‘é‡
    a1 = rot_6d[..., :3]  # (..., 3)
    a2 = rot_6d[..., 3:]  # (..., 3)

    # å½’ä¸€åŒ–ç¬¬ä¸€ä¸ªå‘é‡
    b1 = torch.nn.functional.normalize(a1, dim=-1)

    # æž„é€ ç¬¬äºŒä¸ªå‘é‡ä½¿å…¶æ­£äº¤äºŽç¬¬ä¸€ä¸ª
    b2 = torch.nn.functional.normalize(a2 - torch.sum(b1 * a2, dim=-1, keepdim=True) * b1, dim=-1)

    # å‰ç§¯å¾—åˆ°ç¬¬ä¸‰ä¸ªå‘é‡
    b3 = torch.cross(b1, b2, dim=-1)

    # æž„é€ æ—‹è½¬çŸ©é˜µ
    R = torch.stack([b1, b2, b3], dim=-2)  # (..., 3, 3)

    return R


def matrix_to_rotation_6d(R: torch.Tensor) -> torch.Tensor:
    """
    å°†æ—‹è½¬çŸ©é˜µè½¬æ¢ä¸º6Dè¡¨ç¤º

    Args:
        R: (..., 3, 3) æ—‹è½¬çŸ©é˜µ

    Returns:
        (..., 6) 6Dæ—‹è½¬å‚æ•°
    """
    # å–å‰ä¸¤åˆ—ä½œä¸º6Dè¡¨ç¤º
    rot_6d = torch.cat([R[..., :2, 0], R[..., :2, 1]], dim=-1)
    return rot_6d


def gpu_mem_guard():
    """
    GPUå†…å­˜ç›‘æŽ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    åœ¨CUDAè®¾å¤‡ä¸Šç›‘æŽ§æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
    """
    if torch.cuda.is_available():
        return _CudaMemoryGuard()
    else:
        return _NoOpGuard()


class _CudaMemoryGuard:
    """CUDAæ˜¾å­˜ç›‘æŽ§"""

    def __init__(self):
        self.initial_mem = torch.cuda.memory_allocated()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        current_mem = torch.cuda.memory_allocated()
        delta_mb = (current_mem - self.initial_mem) / 1024 / 1024
        if abs(delta_mb) > 10:  # åªæŠ¥å‘Šæ˜¾è‘—å˜åŒ–
            direction = "å¢žåŠ " if delta_mb > 0 else "å‡å°‘"
            print(".1f")


class _NoOpGuard:
    """ç©ºå®žçŽ°ï¼Œç”¨äºŽéžCUDAçŽ¯å¢ƒ"""

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


def homogeneous_transform(R: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
    """
    æž„é€ é½æ¬¡å˜æ¢çŸ©é˜µ

    Args:
        R: (3, 3) æˆ– (B, 3, 3) æ—‹è½¬çŸ©é˜µ
        t: (3,) æˆ– (B, 3) å¹³ç§»å‘é‡

    Returns:
        (4, 4) æˆ– (B, 4, 4) é½æ¬¡å˜æ¢çŸ©é˜µ
    """
    if R.dim() == 2 and t.dim() == 1:
        T = torch.eye(4, device=R.device, dtype=R.dtype)
        T[:3, :3] = R
        T[:3, 3] = t
        return T

    elif R.dim() == 3 and t.dim() == 2:
        B = R.shape[0]
        T = torch.eye(4, device=R.device, dtype=R.dtype).unsqueeze(0).repeat(B, 1, 1)
        T[:, :3, :3] = R
        T[:, :3, 3] = t
        return T

    else:
        raise ValueError(f"Unsupported tensor dimensions: R {R.shape}, t {t.shape}")


def project_points(points: torch.Tensor, K: torch.Tensor) -> torch.Tensor:
    """
    å°†3Dç‚¹æŠ•å½±åˆ°å›¾åƒå¹³é¢

    Args:
        points: (N, 3) æˆ– (B, N, 3) 3Dç‚¹
        K: (3, 3) æˆ– (B, 3, 3) å†…å‚çŸ©é˜µ

    Returns:
        (N, 2) æˆ– (B, N, 2) åƒç´ åæ ‡
    """
    if points.dim() == 2 and K.dim() == 2:
        # å½’ä¸€åŒ–åæ ‡
        points_norm = points / points[:, 2:3]
        # æŠ•å½±
        uv_homo = torch.matmul(points_norm, K.T)
        return uv_homo[:, :2]

    elif points.dim() == 3 and K.dim() == 3:
        # æ‰¹æ¬¡æƒ…å†µ
        points_norm = points / points[..., 2:3]
        uv_homo = torch.matmul(points_norm, K.transpose(1, 2))
        return uv_homo[..., :2]

    else:
        raise ValueError(f"Unsupported tensor dimensions: points {points.shape}, K {K.shape}")


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    print("ðŸ§ª Testing Math Utils...")

    # æµ‹è¯•6Dæ—‹è½¬è½¬æ¢
    rot_6d = torch.tensor([[1.0, 0.0, 0.0, 0.0, 1.0, 0.0]], dtype=torch.float32)
    R = rotation_6d_to_matrix(rot_6d)
    print(f"6D to Matrix: {R.shape}")
    print(f"Orthogonality check: {torch.allclose(R @ R.transpose(-1, -2), torch.eye(3), atol=1e-6)}")

    # æµ‹è¯•ç‚¹å˜æ¢
    points = torch.randn(10, 3)
    T = torch.eye(4)
    T[:3, 3] = torch.tensor([1.0, 2.0, 3.0])
    transformed = transform_points(points, T)
    print(f"Point transform: {points.shape} -> {transformed.shape}")

    print("âœ… Math utils working correctly!")
