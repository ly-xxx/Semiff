"""
å¯å¾®æ¸²æŸ“å™¨æ¨¡å— - å°è£… nvdiffrast å…‰æ …åŒ–é€»è¾‘
æä¾›ç»Ÿä¸€çš„æ¸²æŸ“æ¥å£ï¼Œæ”¯æŒæ¢¯åº¦ä¼ æ’­
"""

import torch
import logging
import numpy as np

logger = logging.getLogger(__name__)

class DifferentiableRasterizer:
    """å¯å¾®åˆ†å…‰æ …åŒ–æ¸²æŸ“å™¨ï¼ŒåŸºäº nvdiffrast"""

    def __init__(self, H, W, device='cuda'):
        self.H, self.W = H, W
        self.device = device
        self.ctx = None

        try:
            import nvdiffrast.torch as dr
            self.dr = dr
            self.ctx = dr.RasterizeCudaContext(device=device)
            logger.info(f"ğŸŸ¢ nvdiffrast initialized on {device}")
        except ImportError:
            logger.warning("ğŸŸ¡ nvdiffrast not found. Falling back to CPU Mock (No Gradients!).")
            self.ctx = None

    def build_projection_matrix(self, K, near=0.1, far=100.0):
        """æ„å»º OpenGL æŠ•å½±çŸ©é˜µ (NDC)"""
        fx, fy, cx, cy = K[0, 0], K[1, 1], K[0, 2], K[1, 2]
        proj = torch.zeros((4, 4), device=self.device)
        proj[0, 0] = 2 * fx / self.W
        proj[1, 1] = -2 * fy / self.H  # Flip Y for OpenGL
        proj[0, 2] = (self.W - 2 * cx) / self.W
        proj[1, 2] = (self.H - 2 * cy) / self.H
        proj[2, 2] = -(far + near) / (far - near)
        proj[2, 3] = -(2 * far * near) / (far - near)
        proj[3, 2] = -1.0
        return proj

    def render(self, vertices, faces, K, cam_poses=None):
        """
        å¯å¾®åˆ†æ¸²æŸ“

        Args:
            vertices: (B, N, 3) World Space é¡¶ç‚¹
            faces: (M, 3) Int é¢ç´¢å¼•
            K: (B, 3, 3) å†…å‚çŸ©é˜µ
            cam_poses: (B, 4, 4) World-to-Camera å˜æ¢çŸ©é˜µï¼Œå¦‚æœä¸ºNoneåˆ™å‡è®¾é¡¶ç‚¹å·²åœ¨ç›¸æœºåæ ‡ç³»

        Returns:
            (B, H, W) Alpha Mask
        """
        if self.ctx is None:
            # è¿™é‡Œç›´æ¥æŠ›é”™ï¼Œç¡®ä¿ä»£ç èµ°åˆ° nvdiffrast çš„é€»è¾‘é‡Œ
            raise RuntimeError("âŒ nvdiffrast context is None! Check installation.")

        B = vertices.shape[0]

        # 1. MVP Transform (World -> Clip)
        proj = self.build_projection_matrix(K[0]).unsqueeze(0).repeat(B, 1, 1)

        # å¦‚æœæä¾›äº†ç›¸æœºä½å§¿ï¼Œå…ˆå˜æ¢åˆ°ç›¸æœºåæ ‡ç³»
        if cam_poses is not None:
            # World -> Camera transformation
            R_cam = cam_poses[:, :3, :3]  # [B, 3, 3]
            t_cam = cam_poses[:, :3, 3].unsqueeze(1)  # [B, 1, 3]

            # Transform vertices to camera space: v_cam = R_cam @ v_world.T + t_cam
            v_cam = torch.bmm(vertices, R_cam.transpose(1, 2)) + t_cam
        else:
            v_cam = vertices

        # é½æ¬¡åæ ‡
        ones = torch.ones((*v_cam.shape[:2], 1), device=self.device)
        v_homo = torch.cat([v_cam, ones], dim=-1)

        # æŠ•å½±å˜æ¢: v_clip = v_homo @ P.T
        v_clip = torch.bmm(v_homo, proj.transpose(1, 2))

        # 2. å…‰æ …åŒ–
        rast, _ = self.dr.rasterize(self.ctx, v_clip, faces, resolution=[self.H, self.W])

        # 3. æŠ—é”¯é½¿æ’å€¼ (æå– Alpha)
        v_colors = torch.ones_like(vertices)
        mask, _ = self.dr.interpolate(v_colors, rast, faces)
        mask = self.dr.antialias(mask, rast, v_clip, faces)

        mask_final = mask[..., 0]  # è¿”å›å•é€šé“ alpha

        # Debug: æ£€æŸ¥maskçš„ç»Ÿè®¡ä¿¡æ¯
        if torch.rand(1) < 0.01:  # åªåœ¨1%çš„è¿­ä»£ä¸­æ‰“å°ï¼Œé¿å…è¾“å‡ºå¤ªå¤š
            logger.info(f"ğŸ¨ Render Debug - Mask stats: min={mask_final.min():.4f}, max={mask_final.max():.4f}, mean={mask_final.mean():.4f}")

        return mask_final
