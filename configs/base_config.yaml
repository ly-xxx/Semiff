pipeline:
  name: "semiff_pilot"
  workspace: "outputs/auto" # è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
  # "new" = æ¯æ¬¡éƒ½è·‘æ–°çš„; "resume" = æ¥ç€ä¸Šæ¬¡æœ€æ–°çš„è·‘
  mode: "new"
  device: "cuda"

  # ==============================
  # ğŸ•¹ï¸ æ­¥éª¤å¼€å…³ (æ–°å¢)
  # ==============================
  steps:
    step1:
      enable_sam2: true   # å…³æ‰å®ƒï¼Œå¦‚æœå›¾ç‰‡å·²ç»ç”Ÿæˆå¥½äº†
      enable_mast3r: true  # åªè·‘è¿™ä¸ª
      rotate_code: null    # æ‰‹åŠ¨æŒ‡å®šæ—‹è½¬ä»£ç  (0, 1, 2)ï¼Œnullåˆ™è‡ªåŠ¨æ£€æµ‹

  # ğŸ¯ SAM 2 é…ç½®
  sam2:
    checkpoint: "checkpoints/sam2_hiera_large.pt"
    model_cfg: "configs/sam2.1/sam2.1_hiera_l.yaml"
  interactive_mode: true  # å¯ç”¨äº¤äº’å¼æ‰“ç‚¹ (å·¦é”®=ç‰©å—, å³é”®=æœºå™¨äºº)
  # interactive_mode: false # è‡ªåŠ¨æ¨¡å¼ (ä¸­å¿ƒç‚¹æç¤º)

data:
  dataset_name: "example_01"
  # æ•°æ®æ ¹ç›®å½•ï¼Œæ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹
  root_dir: "data/example_01"
  # è§†é¢‘æ–‡ä»¶ (ç›¸å¯¹äº root_dir)
  video_path: "video.mp4"
  # å…³èŠ‚é…ç½®æ–‡ä»¶ (ç›¸å¯¹äº root_dir)
  robot_config: "config/align_pose.json"

robot:
  # URDF è·¯å¾„ (ç›¸å¯¹äº root_dir)
  urdf_rel_path: "robot/rllab_xarm/xarm6_with_gripper_v1.urdf"
  base_link_name: "link_base"

training_3dgs:
  mock: True # å¦‚æœæ²¡å®‰è£… nerfstudioï¼Œè®¾ä¸º True ä»¥è·³è¿‡è®­ç»ƒ
  iterations: 1000
  cull_alpha_thresh: 0.005

optimization:
  lr_pose: 0.002
  lr_trans: 0.01
  lr_scale: 0.005
  iterations: 200

alignment:
  loss_type: "soft_iou" # choices: [soft_iou, mse]
  iou_smooth: 1.0e-6
  # åˆå§‹çŒœæµ‹ (x, y, z)ï¼Œå¾ˆé‡è¦ï¼Œé˜²æ­¢é™·å…¥å±€éƒ¨æœ€ä¼˜
  init_trans: [0.0, 0.0, 1.2]

geometry:
  binding_method: "adaptive" # choices: [adaptive, fixed]
  # è·ç¦»åˆ†å¸ƒçš„ç™¾åˆ†ä½é˜ˆå€¼ (ä¾‹å¦‚ 90%)
  adaptive_percentile: 90.0
  # å¼ºåˆ¶æœ€å¤§é˜ˆå€¼ (ç±³)ï¼Œé˜²æ­¢æŠŠèƒŒæ™¯è¯¯åˆ¤ä¸ºæœºå™¨äºº
  max_threshold: 0.05
